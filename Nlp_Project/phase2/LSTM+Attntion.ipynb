{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2 – Text Summarization using LSTM with Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "ux3EVrmkC2pi",
        "outputId": "04e9cce5-7e1a-41a5-b836-e4eb3598c5f4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2cd5f282-2d68-453b-8835-64b33f16b674\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2cd5f282-2d68-453b-8835-64b33f16b674\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving Text_summarization_dataset.xlsx to Text_summarization_dataset (2).xlsx\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load and Prepare Dataset\n",
        "\n",
        "This block:\n",
        "- Loads the Excel file into a DataFrame\n",
        "- Cleans the column headers (first row was header)\n",
        "- Renames columns to `text` and `summary`\n",
        "- Drops unused rows and resets the index\n",
        "- Shows the first few samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JxEskb_FC-jn",
        "outputId": "af9832c3-75a0-453a-a260-8d6308c2091f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 29335,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29192,\n        \"samples\": [\n          \"\\u0623\\u0641\\u0636\\u0644 \\u062c\\u0632\\u0621 \\u0641\\u064a \\u062a\\u0643\\u0648\\u064a\\u0646 \\u0635\\u062f\\u0627\\u0642\\u0629 \\u0647\\u0648 \\u0623\\u0646 \\u064a\\u0641\\u0647\\u0645 \\u0643\\u0644\\u0627 \\u0645\\u0646 \\u0627\\u0644\\u0637\\u0631\\u0641\\u064a\\u0646 \\u0627\\u0644\\u0622\\u062e\\u0631. \\u0625\\u0630\\u0627 \\u0643\\u0627\\u0646 \\u0635\\u062f\\u064a\\u0642\\u0643 \\u0634\\u064a\\u0648\\u0639\\u064a\\u0627 \\u0648\\u0643\\u0646\\u062a \\u0645\\u0642\\u062a\\u0646\\u0639\\u0627 \\u0628\\u0623\\u064a\\u062f\\u064a\\u0648\\u0644\\u0648\\u062c\\u064a\\u0629 \\u0623\\u062e\\u0631\\u0649\\u060c \\u064a\\u0645\\u0643\\u0646\\u0643\\u0645\\u0627 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0631\\u063a\\u0645 \\u0645\\u0646 \\u0647\\u0630\\u0627 \\u0627\\u0644\\u0627\\u0646\\u0633\\u062c\\u0627\\u0645 \\u0645\\u0639 \\u0628\\u0639\\u0636 \\u0628\\u0635\\u0648\\u0631\\u0629 \\u062c\\u064a\\u062f\\u0629\\u060c \\u0644\\u0646 \\u062a\\u0645\\u062b\\u0644 \\u0627\\u0644\\u0633\\u064a\\u0627\\u0633\\u0629 \\u0623\\u0643\\u062b\\u0631 \\u0645\\u0646 \\u062c\\u0627\\u0646\\u0628 \\u0648\\u0627\\u062d\\u062f \\u0644\\u0627 \\u062a\\u0633\\u062a\\u0637\\u064a\\u0639\\u0627\\u0646 \\u0645\\u0648\\u0627\\u062c\\u0647\\u0629 \\u0628\\u0639\\u0636\\u0643\\u0645\\u0627 \\u0628\\u0648\\u0636\\u0648\\u062d \\u0628\\u062e\\u0635\\u0648\\u0635\\u0647. \\u0627\\u0641\\u0647\\u0645 \\u0623\\u0646 \\u0627\\u062a\\u0641\\u0627\\u0642 \\u0627\\u0644\\u0622\\u0631\\u0627\\u0621 \\u0628\\u064a\\u0646\\u0643 \\u0648\\u0628\\u064a\\u0646 \\u0635\\u062f\\u064a\\u0642\\u0643 \\u0644\\u064a\\u0633 \\u0633\\u0628\\u0628\\u0627 \\u064a\\u062a\\u0648\\u0642\\u0641 \\u0639\\u0644\\u064a\\u0647 \\u062a\\u0648\\u0627\\u0641\\u0642\\u0643\\u0645\\u0627 \\u0643\\u0634\\u062e\\u0635\\u064a\\u0646. \\u0625\\u0646 \\u0644\\u0645 \\u064a\\u0634\\u0627\\u0631\\u0643\\u0643 \\u0623\\u062d\\u062f\\u0647\\u0645 \\u0627\\u0644\\u0631\\u0623\\u064a\\u060c \\u0641\\u0647\\u0630\\u0627 \\u0644\\u0627 \\u064a\\u0639\\u0646\\u064a \\u0623\\u0646\\u0647 \\u064a\\u0633\\u062a\\u062d\\u0642 \\u0627\\u0644\\u0646\\u0642\\u062f \\u0623\\u0648 \\u0627\\u0644\\u0627\\u0633\\u062a\\u062c\\u0648\\u0627\\u0628 \\u0628\\u0634\\u0623\\u0646 \\u0623\\u0641\\u0643\\u0627\\u0631\\u0647 \\u0628\\u0623\\u0633\\u0644\\u0648\\u0628 \\u0641\\u064a\\u0647 \\u0627\\u062a\\u0647\\u0627\\u0645. \\u0627\\u062a\\u0631\\u0643 \\u0642\\u0646\\u0627\\u0639\\u0627\\u062a \\u0635\\u062f\\u064a\\u0642\\u0643 \\u062c\\u0627\\u0646\\u0628\\u0627 \\u0648\\u0639\\u0627\\u0645\\u0644\\u0647 \\u0628\\u0627\\u0644\\u0627\\u062d\\u062a\\u0631\\u0627\\u0645 \\u0627\\u0644\\u0630\\u064a \\u062a\\u0631\\u0649 \\u0623\\u0646\\u0647 \\u0623\\u0647\\u0644\\u0627 \\u0644\\u0647\\u061b \\u064a\\u0646\\u0628\\u063a\\u064a \\u0644\\u0644\\u0635\\u062f\\u0627\\u0642\\u0629 \\u0623\\u0646 \\u062a\\u0643\\u0648\\u0646 \\u0628\\u0639\\u064a\\u062f\\u0629 \\u0639\\u0646 \\u0623\\u0633\\u0644\\u0648\\u0628 \\u0627\\u0644\\u0645\\u0639\\u0627\\u0645\\u0644\\u0629 \\u0627\\u0644\\u0642\\u0627\\u0633\\u064a\\u0629. \\u0625\\u0630\\u0627 \\u0627\\u062d\\u062a\\u0631\\u0645\\u062a \\u0627\\u0644\\u0634\\u062e\\u0635 \\u0633\\u062a\\u062c\\u062f \\u0644\\u062f\\u064a\\u0647 \\u0645\\u0627 \\u0647\\u0648 \\u062c\\u062f\\u064a\\u0631 \\u0628\\u062a\\u0642\\u062f\\u064a\\u0631\\u0643 \\u0648\\u0633\\u062a\\u0631\\u0643\\u0632 \\u0639\\u0644\\u064a\\u0647\\u060c \\u0643\\u0627\\u0644\\u0639\\u0645\\u0644 \\u0628\\u062c\\u062f \\u0648\\u0636\\u0645\\u064a\\u0631 \\u0623\\u0648 \\u0637\\u0631\\u064a\\u0642\\u062a\\u0647 \\u0641\\u064a \\u0627\\u0644\\u062a\\u0639\\u0627\\u0645\\u0644 \\u0645\\u0639 \\u0627\\u0644\\u0646\\u0627\\u0633 \\u0623\\u0648 \\u0642\\u062f\\u0631\\u0627\\u062a \\u0627\\u0644\\u0634\\u062e\\u0635 \\u0623\\u0648 \\u0635\\u0641\\u0627\\u062a\\u0647 \\u0627\\u0644\\u0634\\u062e\\u0635\\u064a\\u0629 \\u0648\\u0645\\u0645\\u064a\\u0632\\u0627\\u062a\\u0647. \\u0644\\u0646 \\u064a\\u0643\\u0648\\u0646 \\u0627\\u0644\\u062c\\u062f\\u0627\\u0644 \\u0628\\u0634\\u0623\\u0646 \\u0627\\u0644\\u0634\\u064a\\u0648\\u0639\\u064a\\u0629 \\u0635\\u0644\\u0629 \\u0648\\u062b\\u064a\\u0642\\u0629 \\u0628\\u064a\\u0646\\u0643\\u0645\\u0627. \\u0623\\u064a \\u0634\\u062e\\u0635 \\u0644\\u062f\\u064a\\u0647 \\u062d\\u064a\\u0627\\u0629 \\u0648\\u0627\\u0647\\u062a\\u0645\\u0627\\u0645\\u0627\\u062a \\u0623\\u062e\\u0631\\u0649 \\u0628\\u062c\\u0627\\u0646\\u0628 \\u0627\\u0644\\u0633\\u064a\\u0627\\u0633\\u0629\\u061b \\u0641\\u0643\\u0631 \\u0645\\u0627 \\u0627\\u0644\\u0630\\u064a \\u062c\\u0630\\u0628\\u0643 \\u0644\\u0644\\u0634\\u062e\\u0635 \\u0645\\u0646 \\u0627\\u0644\\u0628\\u062f\\u0627\\u064a\\u0629\\u060c \\u0643\\u0645\\u062c\\u0627\\u0644 \\u0627\\u0644\\u062f\\u0631\\u0627\\u0633\\u0629 \\u0645\\u062b\\u0644\\u0627 \\u0623\\u0648 \\u0631\\u064a\\u0627\\u0636\\u0629 \\u0645\\u0627 \\u0623\\u0648 \\u0627\\u0644\\u0639\\u0645\\u0644. \\u0623\\u0641\\u0636\\u0644 \\u0627\\u0644\\u0635\\u062f\\u0627\\u0642\\u0627\\u062a \\u062a\\u0643\\u0648\\u0646 \\u0633\\u0648\\u064a\\u0629 \\u0644\\u062a\\u0639\\u062f\\u062f \\u062c\\u0648\\u0627\\u0646\\u0628\\u0647\\u0627\\u060c \\u0641\\u0623\\u0646\\u062a\\u0645\\u0627 \\u0635\\u062f\\u064a\\u0642\\u064a\\u0646 \\u0648\\u0644\\u0633\\u062a\\u0645\\u0627 \\\"\\u0631\\u0641\\u064a\\u0642\\u064a\\u0646\\\" \\u0641\\u064a \\u0627\\u0644\\u0633\\u064a\\u0627\\u0633\\u0629. \\u0644\\u0627 \\u0623\\u062d\\u062f \\u064a\\u062d\\u0628 \\u0623\\u0646 \\u064a\\u062a\\u0639\\u0631\\u0636 \\u0644\\u0644\\u0623\\u0630\\u0649 \\u0628\\u0633\\u0628\\u0628 \\u0623\\u0641\\u0643\\u0627\\u0631\\u0647! \\u062f\\u0627\\u0641\\u0639 \\u0639\\u0646 \\u0635\\u062f\\u064a\\u0642\\u0643 \\u0625\\u0630\\u0627 \\u062a\\u0644\\u0642\\u0649 \\u0645\\u0639\\u0627\\u0645\\u0644\\u0629 \\u0641\\u0638\\u0629 \\u0645\\u0646 \\u0623\\u0634\\u062e\\u0627\\u0635 \\u0645\\u0639\\u0627\\u0631\\u0636\\u064a\\u0646 \\u0644\\u0644\\u0634\\u064a\\u0648\\u0639\\u064a\\u0629\\u060c \\u0633\\u064a\\u0643\\u0648\\u0646 \\u0647\\u0630\\u0627 \\u0623\\u0641\\u0636\\u0644 \\u0634\\u064a\\u0621 \\u062a\\u0641\\u0639\\u0644\\u0647 \\u0644\\u0647\\u0630\\u0647 \\u0627\\u0644\\u0635\\u062f\\u0627\\u0642\\u0629 \\u0648\\u0633\\u062a\\u0641\\u062a\\u062d \\u0623\\u0639\\u064a\\u0646 \\u0627\\u0644\\u0622\\u062e\\u0631\\u064a\\u0646 \\u0639\\u0644\\u0649 \\u0625\\u0645\\u0643\\u0627\\u0646\\u064a\\u0629 \\u062a\\u0642\\u0628\\u0644 \\u0645\\u0646 \\u064a\\u062e\\u062a\\u0644\\u0641 \\u0639\\u0646\\u0647\\u0645 \\u0641\\u064a \\u0627\\u0644\\u0631\\u0623\\u064a.\",\n          \"\\u0625\\u0630\\u0627 \\u0627\\u0633\\u062a\\u0637\\u0639\\u062a \\u0633\\u0645\\u0627\\u0639 \\u0635\\u0648\\u062a \\u0645\\u0646 \\u0633\\u0645\\u0627\\u0639\\u0627\\u062a \\u0627\\u0644\\u0631\\u0623\\u0633 \\u0628\\u0639\\u062f \\u0625\\u0639\\u0627\\u062f\\u0629 \\u062a\\u0634\\u063a\\u064a\\u0644 \\u0647\\u0627\\u062a\\u0641\\u0643\\u060c \\u0641\\u0631\\u0628\\u0645\\u0627 \\u064a\\u0648\\u062c\\u062f \\u0628\\u0639\\u0636 \\u0627\\u0644\\u0628\\u0642\\u0627\\u064a\\u0627 \\u0648\\u0627\\u0644\\u0631\\u0648\\u0627\\u0633\\u0628 \\u0627\\u0644\\u062a\\u064a \\u062a\\u0633\\u062f \\u0645\\u0646\\u0641\\u0630 \\u0627\\u0644\\u0633\\u0645\\u0627\\u0639\\u0627\\u062a. \\u0641\\u0647\\u0630\\u0647 \\u0627\\u0644\\u0628\\u0642\\u0627\\u064a\\u0627 \\u0642\\u062f \\u062a\\u0631\\u0633\\u0644 \\u0625\\u0634\\u0627\\u0631\\u0627\\u062a \\u062e\\u0627\\u0637\\u0626\\u0629 \\u0625\\u0644\\u0649 \\u0627\\u0644\\u0647\\u0627\\u062a\\u0641 \\u0623\\u0646 \\u0633\\u0645\\u0627\\u0639\\u0627\\u062a \\u0627\\u0644\\u0631\\u0623\\u0633 \\u0645\\u062a\\u0635\\u0644\\u0629\\u060c \\u0648\\u0628\\u0627\\u0644\\u062a\\u0627\\u0644\\u064a \\u062a\\u0645\\u0646\\u0639 \\u0627\\u0646\\u0637\\u0644\\u0627\\u0642 \\u0627\\u0644\\u0635\\u0648\\u062a \\u0645\\u0646 \\u0645\\u0643\\u0628\\u0631\\u0627\\u062a \\u0627\\u0644\\u0635\\u0648\\u062a. \\u0627\\u0641\\u0635\\u0644 \\u0633\\u0645\\u0627\\u0639\\u0627\\u062a \\u0627\\u0644\\u0631\\u0623\\u0633 \\u0639\\u0646 \\u0627\\u0644\\u0647\\u0627\\u062a\\u0641 \\u0642\\u0628\\u0644 \\u062a\\u0646\\u0638\\u064a\\u0641 \\u0645\\u0646\\u0641\\u0630 \\u0633\\u0645\\u0627\\u0639\\u0627\\u062a \\u0627\\u0644\\u0631\\u0623\\u0633. cotton swab). \\u0627\\u0636\\u063a\\u0637 \\u0623\\u062d\\u062f \\u0637\\u0631\\u0641\\u064a \\u0627\\u0644\\u0646\\u0643\\u0627\\u0634\\u0629 \\u0628\\u0627\\u0644\\u0625\\u0628\\u0647\\u0627\\u0645 \\u0648\\u0627\\u0644\\u0633\\u0628\\u0627\\u0628\\u0629\\u060c \\u062b\\u0645 \\u0623\\u0632\\u0644 \\u0627\\u0644\\u0642\\u0637\\u0646\\u0629 \\u0627\\u0644\\u0645\\u062a\\u0643\\u0648\\u0631\\u0629. \\u0627\\u0636\\u063a\\u0637 \\u0639\\u0644\\u0649 \\u0646\\u0641\\u0633 \\u0627\\u0644\\u062c\\u0627\\u0646\\u0628 \\u0645\\u0631\\u0629 \\u0623\\u062e\\u0631\\u0649\\u060c \\u0648\\u0644\\u0643\\u0646 \\u0628\\u0631\\u0641\\u0642 \\u0642\\u0644\\u064a\\u0644\\u0627. \\u0644\\u0641 \\u0627\\u0644\\u0646\\u0643\\u0627\\u0634\\u0629 \\u0627\\u0644\\u0642\\u0637\\u0646\\u064a\\u0629 \\u062d\\u0648\\u0644 \\u0645\\u062d\\u0648\\u0631\\u0647\\u0627 \\u0644\\u062a\\u0644\\u0641 \\u0627\\u0644\\u0642\\u0637\\u0646 \\u0627\\u0644\\u0641\\u0627\\u0644\\u062a \\u0628\\u0625\\u062d\\u0643\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0647\\u0627. \\u0636\\u0639 \\u0627\\u0644\\u0646\\u0643\\u0627\\u0634\\u0629 \\u0627\\u0644\\u0642\\u0637\\u0646\\u064a\\u0629  \\u0641\\u064a \\u0645\\u0646\\u0641\\u0630 \\u0627\\u0644\\u0633\\u0645\\u0627\\u0639\\u0627\\u062a. \\u0623\\u062f\\u062e\\u0644 \\u0627\\u0644\\u0637\\u0631\\u0641 \\u0627\\u0644\\u0623\\u0636\\u064a\\u0642 \\u0645\\u0646 \\u0627\\u0644\\u0646\\u0643\\u0627\\u0634\\u0629 \\u0628\\u0631\\u0641\\u0642 \\u0625\\u0644\\u0649 \\u0645\\u0646\\u0641\\u0630 \\u0627\\u0644\\u0633\\u0645\\u0627\\u0639\\u0627\\u062a. \\u062d\\u0631\\u0643 \\u0627\\u0644\\u0646\\u0643\\u0627\\u0634\\u0629 \\u0639\\u062f\\u0629 \\u0645\\u0631\\u0627\\u062a \\u0628\\u062f\\u0627\\u062e\\u0644 \\u0627\\u0644\\u0645\\u0646\\u0641\\u0630\\u060c \\u062b\\u0645 \\u0623\\u062e\\u0631\\u062c\\u0647\\u0627.  \\u062c\\u0631\\u0628 \\u0645\\u0643\\u0628\\u0631\\u0627\\u062a \\u0627\\u0644\\u0635\\u0648\\u062a\\u060c \\u0644\\u062a\\u062a\\u062d\\u0642\\u0642 \\u0645\\u0645\\u0627 \\u0625\\u0630\\u0627 \\u0643\\u0627\\u0646\\u062a \\u062a\\u0639\\u0645\\u0644 \\u0628\\u0634\\u0643\\u0644 \\u0635\\u062d\\u064a\\u062d \\u0627\\u0644\\u0622\\u0646 \\u0623\\u0645 \\u0644\\u0627.   \\u062d\\u0643 \\u0645\\u0646\\u0641\\u0630 \\u0627\\u0644\\u0633\\u0645\\u0627\\u0639\\u0627\\u062a \\u0628\\u0627\\u0644\\u0646\\u0643\\u0627\\u0634\\u0629 \\u0627\\u0644\\u0642\\u0637\\u0646\\u064a\\u0629 \\u0623\\u0633\\u0647\\u0644 \\u0648\\u0623\\u0643\\u062b\\u0631 \\u0627\\u0644\\u0637\\u0631\\u0642 \\u0634\\u064a\\u0648\\u0639\\u0627 \\u0644\\u0644\\u062a\\u0646\\u0638\\u064a\\u0641. \\u0644\\u0627 \\u062a\\u063a\\u0645\\u0633 \\u0637\\u0631\\u0641 \\u0627\\u0644\\u0646\\u0643\\u0627\\u0634\\u0629 \\u0641\\u064a \\u0627\\u0644\\u0645\\u0627\\u0621 \\u0623\\u0648 \\u0627\\u0644\\u0643\\u062d\\u0648\\u0644 \\u0627\\u0644\\u0645\\u062d\\u0645\\u0631\\u060c \\u0641\\u0647\\u0630\\u0627 \\u0642\\u062f \\u064a\\u062f\\u0645\\u0631 \\u062c\\u0647\\u0627\\u0632 \\u0647\\u0627\\u062a\\u0641 \\u0627\\u0644\\u0622\\u064a\\u0641\\u0648\\u0646. \\u0636\\u0639 \\u0627\\u0644\\u0647\\u0627\\u062a\\u0641 \\u0639\\u0644\\u0649 \\u0633\\u0637\\u062d \\u0645\\u0633\\u062a\\u0648. \\u0636\\u0639 \\u0627\\u0644\\u0647\\u0627\\u062a\\u0641 \\u0641\\u064a \\u0648\\u0636\\u0639 \\u064a\\u062c\\u0639\\u0644 \\u0645\\u0646\\u0641\\u0630 \\u0627\\u0644\\u0633\\u0645\\u0627\\u0639\\u0627\\u062a \\u0641\\u064a \\u062c\\u0647\\u062a\\u0643. \\u0648\\u062c\\u0647 \\u0641\\u0648\\u0647\\u0629 \\u0627\\u0644\\u0647\\u0648\\u0627\\u0621 \\u0627\\u0644\\u0645\\u0639\\u0644\\u0628 \\u062a\\u062c\\u0627\\u0647 \\u0645\\u0646\\u0641\\u0630 \\u0627\\u0644\\u0633\\u0645\\u0627\\u0639\\u0627\\u062a \\u062a\\u0628\\u0639\\u0627 \\u0644\\u0644\\u0645\\u0633\\u0627\\u062d\\u0629 \\u0627\\u0644\\u0645\\u0630\\u0643\\u0648\\u0631\\u0629 \\u0641\\u064a \\u0627\\u0644\\u0625\\u0631\\u0634\\u0627\\u062f\\u0627\\u062a. \\u0627\\u0636\\u063a\\u0637 \\u0627\\u0644\\u0639\\u0644\\u0628\\u0629 \\u0642\\u0644\\u064a\\u0644\\u0627\\u060c \\u062b\\u0645 \\u0623\\u0637\\u0644\\u0642\\u0647\\u0627.  \\u0627\\u0644\\u0623\\u0643\\u0633\\u062c\\u064a\\u0646 \\u0627\\u0644\\u0645\\u0639\\u0644\\u0628 \\u0623\\u062f\\u0627\\u0629 \\u0634\\u0627\\u0626\\u0639\\u0629 \\u0644\\u062a\\u0646\\u0638\\u064a\\u0641 \\u0623\\u062c\\u0632\\u0627\\u0621 \\u0627\\u0644\\u062d\\u0627\\u0633\\u0648\\u0628 \\u0648\\u064a\\u0645\\u0643\\u0646\\u0643 \\u0634\\u0631\\u0627\\u0621\\u0647 \\u0645\\u0646 \\u0645\\u062a\\u062c\\u0631 \\u0645\\u0633\\u062a\\u0644\\u0632\\u0645\\u0627\\u062a \\u0627\\u0644\\u062d\\u0627\\u0633\\u0648\\u0628 \\u0623\\u0648 \\u0627\\u0644\\u0625\\u0644\\u0643\\u062a\\u0631\\u0648\\u0646\\u064a\\u0627\\u062a.\",\n          \"\\u064a\\u0639\\u062a\\u0628\\u0631 \\u0627\\u0644\\u0642\\u0644\\u0642 \\u0648\\u0627\\u0644\\u062a\\u0648\\u062a\\u0631 \\u0645\\u0646 \\u0623\\u062d\\u062f \\u0627\\u0644\\u0623\\u0633\\u0628\\u0627\\u0628 \\u0627\\u0644\\u0623\\u0633\\u0627\\u0633\\u064a\\u0629 \\u0644\\u0644\\u0642\\u0630\\u0641 \\u0627\\u0644\\u0645\\u0628\\u0643\\u0631 \\u0644\\u062f\\u0649 \\u0627\\u0644\\u0631\\u062c\\u0627\\u0644.\\u0644\\u0630\\u0644\\u0643 \\u0639\\u0644\\u064a\\u0643 \\u0628\\u0627\\u0644\\u0627\\u0633\\u062a\\u0631\\u062e\\u0627\\u0621\\u060c \\u0648\\u0627\\u0644\\u062a\\u0631\\u0643\\u064a\\u0632 \\u0639\\u0644\\u0649 \\u0639\\u0644\\u0627\\u0642\\u062a\\u0643 \\u0627\\u0644\\u062d\\u0645\\u064a\\u0645\\u064a\\u0629 \\u0628\\u0634\\u0631\\u064a\\u0643\\u0643. \\u062a\\u0630\\u0643\\u0631 \\u0623\\u0646 \\u0645\\u0645\\u0627\\u0631\\u0633\\u0629 \\u0627\\u0644\\u062c\\u0646\\u0633 \\u062a\\u062a\\u0645\\u062d\\u0648\\u0631 \\u062d\\u0648\\u0644 \\u0627\\u0644\\u062d\\u0645\\u064a\\u0645\\u064a\\u0629 \\u0645\\u062b\\u0644\\u0647\\u0627 \\u0645\\u062b\\u0644 \\u0627\\u0644\\u0644\\u0630\\u0629\\u060c \\u0648\\u0623\\u0646 \\u0627\\u0644\\u062c\\u0646\\u0633 \\u0627\\u0644\\u0645\\u0645\\u062a\\u0627\\u0632 \\u064a\\u0623\\u062a\\u064a \\u0628\\u0633\\u0628\\u0628 \\u0627\\u0644\\u062a\\u0646\\u0627\\u063a\\u0645 \\u0628\\u064a\\u0646 \\u0627\\u0644\\u0634\\u0631\\u064a\\u0643\\u064a\\u0646\\u060c \\u0648\\u0644\\u064a\\u0633 \\u0628\\u0633\\u0628\\u0628 \\u0627\\u0644\\u0642\\u062f\\u0631\\u0629 \\u0648\\u0627\\u0644\\u062a\\u062d\\u0645\\u0644. \\u0641\\u064a \\u062d\\u0627\\u0644\\u0629 \\u0634\\u0639\\u0631\\u062a \\u0628\\u0627\\u0644\\u062a\\u0648\\u062a\\u0631\\u060c \\u062e\\u0630 \\u0646\\u0641\\u0633\\u0627 \\u0639\\u0645\\u064a\\u0642\\u0627\\u060c \\u0648\\u062a\\u062d\\u062f\\u062b \\u0645\\u0639 \\u0634\\u0631\\u064a\\u0643\\u0643 \\u0644\\u0628\\u0639\\u0636 \\u0627\\u0644\\u0648\\u0642\\u062a. \\u0625\\u062d\\u062f\\u0649 \\u0627\\u0644\\u0637\\u0631\\u0642 \\u0627\\u0644\\u062a\\u064a \\u064a\\u0633\\u062a\\u062e\\u062f\\u0645\\u0647\\u0627 \\u0627\\u0644\\u0631\\u062c\\u0627\\u0644 \\u0648\\u0627\\u0644\\u0646\\u0633\\u0627\\u0621 \\u0644\\u0625\\u0637\\u0627\\u0644\\u0629 \\u0632\\u0645\\u0646 \\u0627\\u0644\\u0648\\u0635\\u0648\\u0644 \\u0625\\u0644\\u0649 \\u0627\\u0644\\u0646\\u0634\\u0648\\u0629\\u060c \\u0647\\u064a \\u0627\\u0644\\u062a\\u0641\\u0643\\u064a\\u0631 \\u0641\\u064a \\u0645\\u0648\\u0627\\u0636\\u064a\\u0639 \\u0645\\u062e\\u062a\\u0644\\u0641\\u0629 \\u0623\\u062b\\u0646\\u0627\\u0621 \\u0645\\u0645\\u0627\\u0631\\u0633\\u0629 \\u0627\\u0644\\u062c\\u0646\\u0633. \\u0641\\u0643\\u0631 \\u0641\\u064a \\u0628\\u0639\\u0636 \\u0627\\u0644\\u0645\\u0633\\u0627\\u0626\\u0644 \\u0627\\u0644\\u062d\\u0633\\u0627\\u0628\\u064a\\u0629 \\u0627\\u0644\\u0635\\u0639\\u0628\\u0629\\u060c \\u0628\\u064a\\u0646\\u0645\\u0627 \\u062a\\u062f\\u0639 \\u0627\\u0644\\u0625\\u062b\\u0627\\u0631\\u0629 \\u0627\\u0644\\u062a\\u064a \\u062a\\u0634\\u0639\\u0631 \\u0628\\u0647\\u0627 \\u062a\\u062a\\u0633\\u0644\\u0644 \\u0625\\u0644\\u0649 \\u0645\\u0624\\u062e\\u0631\\u0629 \\u0639\\u0642\\u0644\\u0643.  \\u062a\\u062c\\u0646\\u0628 \\u0627\\u0644\\u062a\\u0641\\u0643\\u064a\\u0631 \\u0641\\u064a \\u0627\\u0644\\u0645\\u0648\\u0627\\u0636\\u064a\\u0639 \\u0623\\u0648 \\u0627\\u0644\\u0645\\u0634\\u0627\\u0647\\u062f \\u0627\\u0644\\u062a\\u064a \\u062a\\u0642\\u0644\\u0642\\u0643 \\u0623\\u0648 \\u062a\\u062b\\u0628\\u0637 \\u0645\\u0646 \\u0625\\u062b\\u0627\\u0631\\u062a\\u0643. \\u0641\\u064a \\u0627\\u0644\\u0645\\u0642\\u0627\\u0628\\u0644 \\u0641\\u0643\\u0631 \\u0641\\u064a \\u0634\\u064a\\u0621 \\u0645\\u0627 \\u062a\\u062c\\u0631\\u064a\\u062f\\u064a \\u0645\\u062b\\u0644 \\u062a\\u062e\\u064a\\u0644 \\u0627\\u0644\\u0623\\u0634\\u0643\\u0627\\u0644 \\u0627\\u0644\\u0647\\u0646\\u062f\\u0633\\u064a\\u0629\\u060c \\u0623\\u0648 \\u062a\\u0630\\u0643\\u0631 \\u0643\\u0644\\u0645\\u0627\\u062a \\u0623\\u063a\\u0646\\u064a\\u062a\\u0643 \\u0627\\u0644\\u0645\\u0641\\u0636\\u0644\\u0629. \\u0644\\u0627 \\u062a\\u0632\\u062f \\u0645\\u0646 \\u0642\\u062f\\u0631\\u062a\\u0643 \\u0627\\u0644\\u062c\\u0646\\u0633\\u064a\\u0629 \\u0639\\u0644\\u0649 \\u062d\\u0633\\u0627\\u0628 \\u062a\\u0648\\u0627\\u0635\\u0644\\u0643 \\u0645\\u0639 \\u0634\\u0631\\u064a\\u0643\\u0643. \\u0641\\u0627\\u0644\\u062c\\u0646\\u0633 \\u0627\\u0644\\u0645\\u0637\\u0648\\u0644 \\u0642\\u062f \\u064a\\u0643\\u0648\\u0646 \\u0645\\u0645\\u0644\\u0627 \\u0628\\u0633\\u0628\\u0628 \\u0639\\u062f\\u0645 \\u0627\\u0644\\u062a\\u0631\\u0643\\u064a\\u0632 \\u0628\\u064a\\u0646\\u0643\\u0645\\u0627.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29240,\n        \"samples\": [\n          \"\\u0627\\u0645\\u0644\\u0623 \\u0632\\u062c\\u0627\\u062c\\u0629 \\u0628\\u062e \\u0623\\u0648 \\u0636\\u063a\\u0637 \\u0628\\u062e\\u0644\\u064a\\u0637 \\u0645\\u0643\\u0648\\u0646 \\u0645\\u0646 \\u0646\\u0635\\u0641 \\u0645\\u0642\\u062f\\u0627\\u0631 \\u0645\\u0646 \\u0627\\u0644\\u0645\\u064a\\u0627\\u0647 \\u0648\\u0646\\u0635\\u0641 \\u0645\\u0642\\u062f\\u0627\\u0631 \\u0645\\u0646 \\u0627\\u0644\\u0645\\u0628\\u064a\\u0636. \\u0636\\u0639 \\u062e\\u0644\\u064a\\u0637 \\u0627\\u0644\\u062a\\u0628\\u064a\\u064a\\u0636 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0642\\u0645\\u0627\\u0634 \\u0627\\u0644\\u0645\\u0643\\u0634\\u0648\\u0641 \\u0645\\u0646 \\u0642\\u0637\\u0639\\u0629 \\u0627\\u0644\\u0645\\u0644\\u0627\\u0628\\u0633. \\u0627\\u062a\\u0631\\u0643 \\u0627\\u0644\\u0645\\u0628\\u064a\\u0636 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0642\\u0645\\u0627\\u0634 \\u0644\\u0645\\u062f\\u0629 8 \\u0625\\u0644\\u0649 10 \\u062f\\u0642\\u0627\\u0626\\u0642. \\u0627\\u063a\\u0633\\u0644 \\u0642\\u0637\\u0639\\u0629 \\u0627\\u0644\\u0645\\u0644\\u0627\\u0628\\u0633 \\u0628\\u0639\\u062f \\u0645\\u0631\\u0648\\u0631 \\u0627\\u0644\\u0648\\u0642\\u062a. \\u0639\\u0644\\u0642 \\u0642\\u0637\\u0639\\u0629 \\u0627\\u0644\\u0645\\u0644\\u0627\\u0628\\u0633 \\u0641\\u064a \\u0627\\u0644\\u0647\\u0648\\u0627\\u0621 \\u0643\\u064a \\u062a\\u062c\\u0641 \\u0623\\u0648 \\u0636\\u0639\\u0647\\u0627 \\u0641\\u064a \\u0627\\u0644\\u0645\\u062c\\u0641\\u0641.\",\n          \"\\u062a\\u062d\\u0642\\u0642 \\u0645\\u0646 \\u062a\\u0648\\u0641\\u064a\\u0631 \\u0627\\u0644\\u062a\\u0647\\u0648\\u064a\\u0629 \\u0627\\u0644\\u0643\\u0627\\u0641\\u064a\\u0629 \\u0644\\u0644\\u0645\\u0646\\u0637\\u0642\\u0629. \\u0627\\u0631\\u062a\\u062f \\u0627\\u0644\\u0646\\u0638\\u0627\\u0631\\u0627\\u062a \\u0627\\u0644\\u0648\\u0627\\u0642\\u064a\\u0629 \\u0648\\u0627\\u0644\\u0642\\u0641\\u0627\\u0632\\u0627\\u062a \\u0627\\u0644\\u062b\\u0642\\u064a\\u0644\\u0629. \\u0636\\u0639 \\u0627\\u0644\\u062e\\u064a\\u0634 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0623\\u0631\\u0636. \\u062a\\u062e\\u0644\\u0635 \\u0645\\u0646 \\u0627\\u0644\\u0633\\u0646\\u0627\\u062c \\u0627\\u0644\\u0631\\u062e\\u0648 \\u0639\\u0646 \\u0623\\u0633\\u0637\\u062d \\u0627\\u0644\\u062c\\u062f\\u0631\\u0627\\u0646. \\u0623\\u0632\\u0644 \\u0627\\u0644\\u0633\\u0646\\u0627\\u062c \\u0628\\u062b\\u0644\\u0627\\u062b\\u064a \\u0641\\u0648\\u0633\\u0641\\u0627\\u062a \\u0627\\u0644\\u0635\\u0648\\u062f\\u064a\\u0648\\u0645. \\u0627\\u0628\\u062d\\u062b \\u0639\\u0646 \\u0645\\u0646\\u062a\\u062c \\u062a\\u0646\\u0638\\u064a\\u0641 \\u062a\\u062c\\u0627\\u0631\\u064a. \\u062d\\u0627\\u0648\\u0644 \\u0623\\u0646 \\u062a\\u0632\\u064a\\u0644 \\u0631\\u0627\\u0626\\u062d\\u0629 \\u0627\\u0644\\u062f\\u062e\\u0627\\u0646 \\u0639\\u0646 \\u062c\\u062f\\u0631\\u0627\\u0646\\u0643. \\u0627\\u0633\\u062a\\u0634\\u0631 \\u0645\\u062a\\u062e\\u0635\\u0635\\u0627 \\u0641\\u064a \\u062a\\u0644\\u0641\\u064a\\u0627\\u062a \\u0627\\u0644\\u062f\\u062e\\u0627\\u0646 \\u0625\\u0630\\u0627 \\u0643\\u0627\\u0646\\u062a \\u0634\\u062f\\u064a\\u062f\\u0629 \\u0641\\u064a \\u0628\\u064a\\u062a\\u0643.\",\n          \"\\u0627\\u0644\\u062a\\u0639\\u0631\\u0641 \\u0639\\u0644\\u0649 \\u0623\\u0648\\u0644\\u0648\\u064a\\u0627\\u062a\\u0643. \\u0642\\u0644 \\u0644\\u0627 \\u0639\\u0646\\u062f\\u0645\\u0627 \\u064a\\u0643\\u0648\\u0646 \\u0644\\u062f\\u064a\\u0643 \\u0627\\u0644\\u0643\\u062b\\u064a\\u0631 \\u0644\\u062a\\u0641\\u0639\\u0644\\u0647. \\u0643\\u0646 \\u0648\\u0627\\u0642\\u0639\\u064a\\u0627 \\u0628\\u0634\\u0623\\u0646 \\u0642\\u062f\\u0631\\u0627\\u062a\\u0643. \\u062e\\u0630 \\u0627\\u0644\\u0648\\u0642\\u062a \\u0627\\u0644\\u0630\\u064a \\u062a\\u062d\\u062a\\u0627\\u062c\\u0647 \\u0644\\u0635\\u0646\\u0639 \\u0627\\u0644\\u0642\\u0631\\u0627\\u0631\\u0627\\u062a \\u0627\\u0644\\u0635\\u062d\\u064a\\u062d\\u0629. \\u0627\\u0635\\u0646\\u0639 \\u0642\\u0627\\u0626\\u0645\\u0629 \\u0645\\u062d\\u0627\\u0633\\u0646 \\u0648\\u0645\\u0633\\u0627\\u0648\\u0649\\u0621 \\u0645\\u0639 \\u0648\\u0636\\u0639 \\u0627\\u0644\\u0623\\u0647\\u062f\\u0627\\u0641 \\u0637\\u0648\\u064a\\u0644\\u0629 \\u0627\\u0644\\u0645\\u062f\\u0649 \\u0641\\u064a \\u0627\\u0644\\u062d\\u0633\\u0628\\u0627\\u0646.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "dataset"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ce47811c-a737-40ea-9fb2-8bdbcd7aa0b7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>يكون سعر الفاكهة والخضراوات في موسم إنباتها أق...</td>\n",
              "      <td>تناول الفاكهة والخضراوات في موسمها. تعرف على أ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>الأطعمة الصحية ليست باهظة الثمن بالضرورة، بل ف...</td>\n",
              "      <td>فضل خيارات الأطعمة الأرخص ثمنا. تباطأ في استهل...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>استفد من حديقتك المنزلية أو أصيص الزرع الصغير ...</td>\n",
              "      <td>ازرع كل ما يمكنك من خضراوات وفاكهة. اطه بنفسك ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>تساعدك الخطط المسبقة في كل نواحي حياتك على وضع...</td>\n",
              "      <td>خطط مسبقا لوجباتك الرئيسية لمدة أسبوع. التزم ب...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>نظرا لأن السبب الرئيسي لضغط العين هو أن ثقافة ...</td>\n",
              "      <td>قلل وقت التعرض للشاشات. اذهب إلى الطبيب.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce47811c-a737-40ea-9fb2-8bdbcd7aa0b7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ce47811c-a737-40ea-9fb2-8bdbcd7aa0b7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ce47811c-a737-40ea-9fb2-8bdbcd7aa0b7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-58dd1d88-16ab-48ca-94ca-95666d86cd33\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-58dd1d88-16ab-48ca-94ca-95666d86cd33')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-58dd1d88-16ab-48ca-94ca-95666d86cd33 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "0                                               text  \\\n",
              "0  يكون سعر الفاكهة والخضراوات في موسم إنباتها أق...   \n",
              "1  الأطعمة الصحية ليست باهظة الثمن بالضرورة، بل ف...   \n",
              "2  استفد من حديقتك المنزلية أو أصيص الزرع الصغير ...   \n",
              "3  تساعدك الخطط المسبقة في كل نواحي حياتك على وضع...   \n",
              "4  نظرا لأن السبب الرئيسي لضغط العين هو أن ثقافة ...   \n",
              "\n",
              "0                                            summary  \n",
              "0  تناول الفاكهة والخضراوات في موسمها. تعرف على أ...  \n",
              "1  فضل خيارات الأطعمة الأرخص ثمنا. تباطأ في استهل...  \n",
              "2  ازرع كل ما يمكنك من خضراوات وفاكهة. اطه بنفسك ...  \n",
              "3  خطط مسبقا لوجباتك الرئيسية لمدة أسبوع. التزم ب...  \n",
              "4           قلل وقت التعرض للشاشات. اذهب إلى الطبيب.  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_excel(\"Text_summarization_dataset.xlsx\")\n",
        "\n",
        "dataset.columns = dataset.iloc[0]\n",
        "dataset = dataset.drop(0)\n",
        "\n",
        "\n",
        "dataset = dataset.rename(columns={\"summary\": \"summary\", \"text\": \"text\"})\n",
        "\n",
        "\n",
        "dataset = dataset[[\"text\", \"summary\"]]\n",
        "dataset.reset_index(drop=True, inplace=True)\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tokenization with spaCy\n",
        "\n",
        "Loads a multilingual spaCy model for tokenizing Arabic (or multilingual) text.  \n",
        "The `tokenize_ar` function splits text into a list of tokens.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfsLXVlrExvY"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"xx_ent_wiki_sm\")\n",
        "\n",
        "def tokenize_ar(text):\n",
        "    return [tok.text for tok in nlp(text)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tokenization Sample\n",
        "\n",
        "Prints the original text and the list of tokens produced by the `tokenize_ar` function for a single sample.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sV6cCm_dFFRv",
        "outputId": "53322af3-9221-4017-bde0-867869c8c926"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: يكون سعر الفاكهة والخضراوات في موسم إنباتها أقل من غيره من المواسم، وستلجأ محلات الخضروات إلى عرض الفاكهة بأسعار مناسبة في موسمها بسبب توفر المنتجات وزيادة الطلب عليها خلال تلك الفترات. لا يقتصر الأمر على السعر الأقل، بل سيكون طعامك من الخضراوات والفاكهة أشهى وألذ عند تناوله في موسمه.   في فصل الخريف: التفاح والتين والبنجر والكمثرى والقرنبيط والكرنب واليقطين في فصل الشتاء: (الخضراوات) الملفوف والفاصوليا والبازلاء والبصل (الفواكه)  البطاطا الحلوة والأفوكادو والبرتقال والتفاح والموز واليوسفى والرمان والعنب. في فصل الربيع: السبانخ والجزر والكوسة والبصل الأخضر  والطماطم والخضراوات الورقية والفراولة والمشمش. في فصل الصيف: الصيف هو فصل البطيخ، وكذلك الأمر بالنسبة للذرة والتوت. سوف تلاحظ توفر هذه الخضراوات والفواكهة المهمة على مدار العام كله بشكل أو آخر، ولكنها تكون بأرخص أسعارها في فصل الصيف، وهو ما يمكنك من شراء كميات كبيرة منها وتخزينها أو تجميدها في المجمد (الفريزر). الأفضل لصحتك البدنية والمالية على حد سواء هو تناول الفواكه والخضراوات والأطعمة الطازجة عامة، ولكن في بعض الحالات قد يكون من الأرخص بالنسبة لك الاعتماد على الطعام المعبأ. سوف تحصل منه على نفس الفوائد الغذائية بشرط التأكد من أنه غير مضاف إليه أي ملح أو سكر أو مواد مصنعة.  اتبع هذه النصيحة مع الفواكه والخضراوات وكذلك مع مصادر البروتينات؛ قد يكون سعر الفراخ المجمدة مثلا أرخص من الطازجة، وبالمثل في حالة عبوات التونة والسالمون مقارنة بشراء السمك من كلا النوعين طازجا. تحرص العديد من محلات الأطعمة الغذائية باختلاف أنواعها على تقديم عروض خاصة لعملائها بوتيرة أسبوعية، وهو ما يمكنك الاطلاع عليه عبر مطبوعات الإعلانات وصفحاتهم الرسمية عبر وسائل التواصل الاجتماعي. اغتنم أوقات العروض على واحدة من الأطعمة وجهز نفسك واهجم على المحل لاقتناء أكبر كمية ممكنة على أمل تخزينها في منزلك بشكل أو آخر؛ إنها صفقة لا تعوض. يمكنك تخزين أغلبية أنواع اللحوم على سبيل المثال، لذا بمجرد رؤيتك لهذا العرض الخاص على صدور الدجاج في واحدة من المحلات الكبرى، أسرع فورا واشتر كمية مناسبة يمكنك تخزين الزائد منها عن حاجتك لوقت لاحق. إنها مهارة تتقنها كل ربات البيوت وإلا لما نجحت جداتنا وأمهاتنا في تربية عدد ضخم من الأبناء بقدر ضئيل من المرتبات، وبنسبة كبيرة أنك تحرصين بدورك على شراء أرخص العلامات التجارية المقبولة وقد سبق لك إجراء مثل هذه المقارنة، لكن ما نود الإشارة إليه هو عدم الارتكان دائما لنفس خيار الشراء بوصفه الأرخص ثمنا، لأنه ربما كان كذلك منذ شهور، بينما قد توفر في السوق الآن خيار بديل بسعر أفضل. عملية المقارنة بين الأسعار مهمة ضرورية قبل كل عملية شراء قدر الإمكان، لذا لا تفقدي يقظتك أبدا. عادة ما يتاح كذلك عروض مميزة على شراء الكميات الكبيرة أو خصما على منتج معين لفترة محدودة، لذا من خلال عملية البحث والمقارنة المستمرة يمكنك الذهاب إلى السوق وشراء كل ما يلزمك بأفضل سعر ممكن.    انقلي بصرك لأعلى وأسفل رفوف المحلات التجارية، فغالبا ما يتعمد البائعون وضع السلع الأغلى ثمنا في مستوى العين لكي يبادر المستهلكون دائما لاقتنائها وإغفال النظر عن غيرها من الخيارات رخيصة الثمن. ابحثي عن السلع والأطعمة المحلية والمصنعة باسم المتجر التجاري نفسه، والتي عادة ما تكون بسعر أقل مقارنة بالعلامات التجارية الكبرى. سوف تقف أمام البائع وتدفع رقما ضخما نظير شرائك للسلع بالجملة، ولكن بحسبة بسيطة ستكتشف أنك حصلت على الوحدة الواحدة من المنتج بثمن أرخص من الشراء بالقطعة. توجد متاجر خاصة بالبيع بالجملة كما يتوفر هذا الاختيار في كل المحلات العادية كذلك؛ عند شرائك لدستة من منتج معين، سيكون إجمالي السعر أرخص من شراء نفس عدد العبوات بشكل منفرد على أكثر من مرة.   يمكنك الشراء بالجملة من متاجر السلع المعبئة (السوبرماركت) ونفس الأمر بالنسبة لمحلات الفاكهة والخضراوات والسلع الغذائية الصحية (العضوية). يحرص البائعون على توفير سلع مثل: الحبوب والبقول والمكرونة (غير المعبئة) والمكسرات والدقيق والسكر وما شابه، للشراء بالجملة. حاول شراء السلع سابقة الذكر من المحلات المدعومة تبعا لوزارة التموين في بلدك، فقد تحصل منها على نفس السلع بنفس جودة العلامات التجارية الكبرى ولكن بسعر مخفض. ضع نصب عينيك حقيقة وجود فترة زمنية قصوى يمكنك خلالها استهلاك ما اشتريته من سلع بالجملة، فمهما كان من الممكن تخزينها أو تجميدها، ستجد نفسك أمام حقيقة أن ما اشتريته معرضا لانتهاء صلاحيته بعد عدة شهور. استوعب مناسبة تلك الكمية الكبيرة لمعدل استهلاكك أنت وأسرتك (ورغبتهم في أكلها أصلا) من الأطعمة ودون أن تنسى إدراج فترة صلاحية المنتج ضمن تلك المعادلة الحسابية الصعبة، فلا فائدة من شراء شيء رخيص ولكنه سيلقى على الأرض بلا فائدة عندما يصبح غير صالح للاستخدام. لا تترك قسيمة شراء تهرب من تحت يدك بمجرد وجود فرصة للحصول عليها، لكن على الجانب الآخر لا تشتر سوى السلع والمنتجات التي تعرف أنك بحاجة إلى استخدامها. لا فائدة من شراء منتج لا تشتريه في العادة -مهما كان رخيص الثمن- لأنك ستنفق أموالك على ما لا تحتاجه وما لن ترغب في استخدامه، وستضيع أموالك على الأرض بلا فائدة، وستدرك وقتها أنها كانت صفقة خاسرة.  يمكنك إيجاد قسائم الشراء عبر الإنترنت أو في الجرائد والمجلات، كما يمكنك الاستفادة حديثا من تطبيقات قسائم الشراء على الهواتف الذكية. قد تكون مؤهلا للاشتراك في واحدة من برامج دعم الغذاء لمحدودي الدخل في بلدك، وهي الجهات التي توفر الطعام بأسعار مدعومة للمحتاجين.   تختلف أنظمة دعم التموين والطعام من بلد لآخر، لذانص مائل ستحتاج لإجراء عملية بحث بسيطة لمعرفة إجراءات التسجيل في مثل هذه البرامج. قد تجد برامج مخصصة للعاطلين من الأفراد أو السيدات قليلات الدخل أو للأسر كبيرة العدد وما شابه. قد لا تتوفر لك في المتاجر التابعة لمثل برامج الدعم تلك كل ما تطمع وتشتهيه من سلع، ولكنك ستجد بها الحد الأدنى من احتياجاتك من الأطعمة الصحية والضروريات اللازمة من الطعام.   اذهب إلى المكتب المحلي المخصص للتقدم بطلب الحصول على الدعم أو يمكنك التقدم عبر المنصات والمواقع الإلكترونية في حال توفرها. تواصلي مع الجهات المسؤولة عن تقديم الدعم للعاطلين وللسيدات محدودات الدخل وما شابه في مدينتك لمعرفة كيفية التقدم للاشتراك في برامج الدعم المماثلة. تجد العديد من السلع الغذائية الأرخص سعرا في المتاجر التابعة مباشرة للمزارع المحلية، وإن كنت ستواجه صعوبة في الحصول على احتياجك من السلع نظرا لضغط الطلب وقلة المعروض من منتجات غالبا. إنها أطعمة طازجة ولم يضاف إليها تكاليف النقل وأرباح الكثير من الموزعين والبائعين، لذا ستقدر على الحصول عليها بسعر أرخص وجودة أفضل. استوعب فقط أنك لن تملك رفاهية تأجيل تناولها كونها لا تظل على حالتها فترات طويلة مقارنة بغيرها من السلع الغذائية المزروعة لتحمل مشقة النقل والفترات الزمنية الطويلة قبل التناول. الميزة الإيجابية أنك ستقدر على تناول أطعمة أفضل مذاقا وطزاجة.  قد تجد بعض المزارع المحلية المدرجة ضمن برامج الدعم الحكومي للطعام والتي توفر للمستحقين إمكانية شراء الفاكهة والخضراوات بسعر أقل.\n",
            "Tokens: ['يكون', 'سعر', 'الفاكهة', 'والخضراوات', 'في', 'موسم', 'إنباتها', 'أقل', 'من', 'غيره', 'من', 'المواسم', '،', 'وستلجأ', 'محلات', 'الخضروات', 'إلى', 'عرض', 'الفاكهة', 'بأسعار', 'مناسبة', 'في', 'موسمها', 'بسبب', 'توفر', 'المنتجات', 'وزيادة', 'الطلب', 'عليها', 'خلال', 'تلك', 'الفترات', '.', 'لا', 'يقتصر', 'الأمر', 'على', 'السعر', 'الأقل', '،', 'بل', 'سيكون', 'طعامك', 'من', 'الخضراوات', 'والفاكهة', 'أشهى', 'وألذ', 'عند', 'تناوله', 'في', 'موسمه', '.', '  ', 'في', 'فصل', 'الخريف', ':', 'التفاح', 'والتين', 'والبنجر', 'والكمثرى', 'والقرنبيط', 'والكرنب', 'واليقطين', 'في', 'فصل', 'الشتاء', ':', '(', 'الخضراوات', ')', 'الملفوف', 'والفاصوليا', 'والبازلاء', 'والبصل', '(', 'الفواكه', ')', ' ', 'البطاطا', 'الحلوة', 'والأفوكادو', 'والبرتقال', 'والتفاح', 'والموز', 'واليوسفى', 'والرمان', 'والعنب', '.', 'في', 'فصل', 'الربيع', ':', 'السبانخ', 'والجزر', 'والكوسة', 'والبصل', 'الأخضر', ' ', 'والطماطم', 'والخضراوات', 'الورقية', 'والفراولة', 'والمشمش', '.', 'في', 'فصل', 'الصيف', ':', 'الصيف', 'هو', 'فصل', 'البطيخ', '،', 'وكذلك', 'الأمر', 'بالنسبة', 'للذرة', 'والتوت', '.', 'سوف', 'تلاحظ', 'توفر', 'هذه', 'الخضراوات', 'والفواكهة', 'المهمة', 'على', 'مدار', 'العام', 'كله', 'بشكل', 'أو', 'آخر', '،', 'ولكنها', 'تكون', 'بأرخص', 'أسعارها', 'في', 'فصل', 'الصيف', '،', 'وهو', 'ما', 'يمكنك', 'من', 'شراء', 'كميات', 'كبيرة', 'منها', 'وتخزينها', 'أو', 'تجميدها', 'في', 'المجمد', '(', 'الفريزر', ')', '.', 'الأفضل', 'لصحتك', 'البدنية', 'والمالية', 'على', 'حد', 'سواء', 'هو', 'تناول', 'الفواكه', 'والخضراوات', 'والأطعمة', 'الطازجة', 'عامة', '،', 'ولكن', 'في', 'بعض', 'الحالات', 'قد', 'يكون', 'من', 'الأرخص', 'بالنسبة', 'لك', 'الاعتماد', 'على', 'الطعام', 'المعبأ', '.', 'سوف', 'تحصل', 'منه', 'على', 'نفس', 'الفوائد', 'الغذائية', 'بشرط', 'التأكد', 'من', 'أنه', 'غير', 'مضاف', 'إليه', 'أي', 'ملح', 'أو', 'سكر', 'أو', 'مواد', 'مصنعة', '.', ' ', 'اتبع', 'هذه', 'النصيحة', 'مع', 'الفواكه', 'والخضراوات', 'وكذلك', 'مع', 'مصادر', 'البروتينات', '؛', 'قد', 'يكون', 'سعر', 'الفراخ', 'المجمدة', 'مثلا', 'أرخص', 'من', 'الطازجة', '،', 'وبالمثل', 'في', 'حالة', 'عبوات', 'التونة', 'والسالمون', 'مقارنة', 'بشراء', 'السمك', 'من', 'كلا', 'النوعين', 'طازجا', '.', 'تحرص', 'العديد', 'من', 'محلات', 'الأطعمة', 'الغذائية', 'باختلاف', 'أنواعها', 'على', 'تقديم', 'عروض', 'خاصة', 'لعملائها', 'بوتيرة', 'أسبوعية', '،', 'وهو', 'ما', 'يمكنك', 'الاطلاع', 'عليه', 'عبر', 'مطبوعات', 'الإعلانات', 'وصفحاتهم', 'الرسمية', 'عبر', 'وسائل', 'التواصل', 'الاجتماعي', '.', 'اغتنم', 'أوقات', 'العروض', 'على', 'واحدة', 'من', 'الأطعمة', 'وجهز', 'نفسك', 'واهجم', 'على', 'المحل', 'لاقتناء', 'أكبر', 'كمية', 'ممكنة', 'على', 'أمل', 'تخزينها', 'في', 'منزلك', 'بشكل', 'أو', 'آخر', '؛', 'إنها', 'صفقة', 'لا', 'تعوض', '.', 'يمكنك', 'تخزين', 'أغلبية', 'أنواع', 'اللحوم', 'على', 'سبيل', 'المثال', '،', 'لذا', 'بمجرد', 'رؤيتك', 'لهذا', 'العرض', 'الخاص', 'على', 'صدور', 'الدجاج', 'في', 'واحدة', 'من', 'المحلات', 'الكبرى', '،', 'أسرع', 'فورا', 'واشتر', 'كمية', 'مناسبة', 'يمكنك', 'تخزين', 'الزائد', 'منها', 'عن', 'حاجتك', 'لوقت', 'لاحق', '.', 'إنها', 'مهارة', 'تتقنها', 'كل', 'ربات', 'البيوت', 'وإلا', 'لما', 'نجحت', 'جداتنا', 'وأمهاتنا', 'في', 'تربية', 'عدد', 'ضخم', 'من', 'الأبناء', 'بقدر', 'ضئيل', 'من', 'المرتبات', '،', 'وبنسبة', 'كبيرة', 'أنك', 'تحرصين', 'بدورك', 'على', 'شراء', 'أرخص', 'العلامات', 'التجارية', 'المقبولة', 'وقد', 'سبق', 'لك', 'إجراء', 'مثل', 'هذه', 'المقارنة', '،', 'لكن', 'ما', 'نود', 'الإشارة', 'إليه', 'هو', 'عدم', 'الارتكان', 'دائما', 'لنفس', 'خيار', 'الشراء', 'بوصفه', 'الأرخص', 'ثمنا', '،', 'لأنه', 'ربما', 'كان', 'كذلك', 'منذ', 'شهور', '،', 'بينما', 'قد', 'توفر', 'في', 'السوق', 'الآن', 'خيار', 'بديل', 'بسعر', 'أفضل', '.', 'عملية', 'المقارنة', 'بين', 'الأسعار', 'مهمة', 'ضرورية', 'قبل', 'كل', 'عملية', 'شراء', 'قدر', 'الإمكان', '،', 'لذا', 'لا', 'تفقدي', 'يقظتك', 'أبدا', '.', 'عادة', 'ما', 'يتاح', 'كذلك', 'عروض', 'مميزة', 'على', 'شراء', 'الكميات', 'الكبيرة', 'أو', 'خصما', 'على', 'منتج', 'معين', 'لفترة', 'محدودة', '،', 'لذا', 'من', 'خلال', 'عملية', 'البحث', 'والمقارنة', 'المستمرة', 'يمكنك', 'الذهاب', 'إلى', 'السوق', 'وشراء', 'كل', 'ما', 'يلزمك', 'بأفضل', 'سعر', 'ممكن', '.', '   ', 'انقلي', 'بصرك', 'لأعلى', 'وأسفل', 'رفوف', 'المحلات', 'التجارية', '،', 'فغالبا', 'ما', 'يتعمد', 'البائعون', 'وضع', 'السلع', 'الأغلى', 'ثمنا', 'في', 'مستوى', 'العين', 'لكي', 'يبادر', 'المستهلكون', 'دائما', 'لاقتنائها', 'وإغفال', 'النظر', 'عن', 'غيرها', 'من', 'الخيارات', 'رخيصة', 'الثمن', '.', 'ابحثي', 'عن', 'السلع', 'والأطعمة', 'المحلية', 'والمصنعة', 'باسم', 'المتجر', 'التجاري', 'نفسه', '،', 'والتي', 'عادة', 'ما', 'تكون', 'بسعر', 'أقل', 'مقارنة', 'بالعلامات', 'التجارية', 'الكبرى', '.', 'سوف', 'تقف', 'أمام', 'البائع', 'وتدفع', 'رقما', 'ضخما', 'نظير', 'شرائك', 'للسلع', 'بالجملة', '،', 'ولكن', 'بحسبة', 'بسيطة', 'ستكتشف', 'أنك', 'حصلت', 'على', 'الوحدة', 'الواحدة', 'من', 'المنتج', 'بثمن', 'أرخص', 'من', 'الشراء', 'بالقطعة', '.', 'توجد', 'متاجر', 'خاصة', 'بالبيع', 'بالجملة', 'كما', 'يتوفر', 'هذا', 'الاختيار', 'في', 'كل', 'المحلات', 'العادية', 'كذلك', '؛', 'عند', 'شرائك', 'لدستة', 'من', 'منتج', 'معين', '،', 'سيكون', 'إجمالي', 'السعر', 'أرخص', 'من', 'شراء', 'نفس', 'عدد', 'العبوات', 'بشكل', 'منفرد', 'على', 'أكثر', 'من', 'مرة', '.', '  ', 'يمكنك', 'الشراء', 'بالجملة', 'من', 'متاجر', 'السلع', 'المعبئة', '(', 'السوبرماركت', ')', 'ونفس', 'الأمر', 'بالنسبة', 'لمحلات', 'الفاكهة', 'والخضراوات', 'والسلع', 'الغذائية', 'الصحية', '(', 'العضوية', ')', '.', 'يحرص', 'البائعون', 'على', 'توفير', 'سلع', 'مثل', ':', 'الحبوب', 'والبقول', 'والمكرونة', '(', 'غير', 'المعبئة', ')', 'والمكسرات', 'والدقيق', 'والسكر', 'وما', 'شابه', '،', 'للشراء', 'بالجملة', '.', 'حاول', 'شراء', 'السلع', 'سابقة', 'الذكر', 'من', 'المحلات', 'المدعومة', 'تبعا', 'لوزارة', 'التموين', 'في', 'بلدك', '،', 'فقد', 'تحصل', 'منها', 'على', 'نفس', 'السلع', 'بنفس', 'جودة', 'العلامات', 'التجارية', 'الكبرى', 'ولكن', 'بسعر', 'مخفض', '.', 'ضع', 'نصب', 'عينيك', 'حقيقة', 'وجود', 'فترة', 'زمنية', 'قصوى', 'يمكنك', 'خلالها', 'استهلاك', 'ما', 'اشتريته', 'من', 'سلع', 'بالجملة', '،', 'فمهما', 'كان', 'من', 'الممكن', 'تخزينها', 'أو', 'تجميدها', '،', 'ستجد', 'نفسك', 'أمام', 'حقيقة', 'أن', 'ما', 'اشتريته', 'معرضا', 'لانتهاء', 'صلاحيته', 'بعد', 'عدة', 'شهور', '.', 'استوعب', 'مناسبة', 'تلك', 'الكمية', 'الكبيرة', 'لمعدل', 'استهلاكك', 'أنت', 'وأسرتك', '(', 'ورغبتهم', 'في', 'أكلها', 'أصلا', ')', 'من', 'الأطعمة', 'ودون', 'أن', 'تنسى', 'إدراج', 'فترة', 'صلاحية', 'المنتج', 'ضمن', 'تلك', 'المعادلة', 'الحسابية', 'الصعبة', '،', 'فلا', 'فائدة', 'من', 'شراء', 'شيء', 'رخيص', 'ولكنه', 'سيلقى', 'على', 'الأرض', 'بلا', 'فائدة', 'عندما', 'يصبح', 'غير', 'صالح', 'للاستخدام', '.', 'لا', 'تترك', 'قسيمة', 'شراء', 'تهرب', 'من', 'تحت', 'يدك', 'بمجرد', 'وجود', 'فرصة', 'للحصول', 'عليها', '،', 'لكن', 'على', 'الجانب', 'الآخر', 'لا', 'تشتر', 'سوى', 'السلع', 'والمنتجات', 'التي', 'تعرف', 'أنك', 'بحاجة', 'إلى', 'استخدامها', '.', 'لا', 'فائدة', 'من', 'شراء', 'منتج', 'لا', 'تشتريه', 'في', 'العادة', '-مهما', 'كان', 'رخيص', 'الثمن-', 'لأنك', 'ستنفق', 'أموالك', 'على', 'ما', 'لا', 'تحتاجه', 'وما', 'لن', 'ترغب', 'في', 'استخدامه', '،', 'وستضيع', 'أموالك', 'على', 'الأرض', 'بلا', 'فائدة', '،', 'وستدرك', 'وقتها', 'أنها', 'كانت', 'صفقة', 'خاسرة', '.', ' ', 'يمكنك', 'إيجاد', 'قسائم', 'الشراء', 'عبر', 'الإنترنت', 'أو', 'في', 'الجرائد', 'والمجلات', '،', 'كما', 'يمكنك', 'الاستفادة', 'حديثا', 'من', 'تطبيقات', 'قسائم', 'الشراء', 'على', 'الهواتف', 'الذكية', '.', 'قد', 'تكون', 'مؤهلا', 'للاشتراك', 'في', 'واحدة', 'من', 'برامج', 'دعم', 'الغذاء', 'لمحدودي', 'الدخل', 'في', 'بلدك', '،', 'وهي', 'الجهات', 'التي', 'توفر', 'الطعام', 'بأسعار', 'مدعومة', 'للمحتاجين', '.', '  ', 'تختلف', 'أنظمة', 'دعم', 'التموين', 'والطعام', 'من', 'بلد', 'لآخر', '،', 'لذانص', 'مائل', 'ستحتاج', 'لإجراء', 'عملية', 'بحث', 'بسيطة', 'لمعرفة', 'إجراءات', 'التسجيل', 'في', 'مثل', 'هذه', 'البرامج', '.', 'قد', 'تجد', 'برامج', 'مخصصة', 'للعاطلين', 'من', 'الأفراد', 'أو', 'السيدات', 'قليلات', 'الدخل', 'أو', 'للأسر', 'كبيرة', 'العدد', 'وما', 'شابه', '.', 'قد', 'لا', 'تتوفر', 'لك', 'في', 'المتاجر', 'التابعة', 'لمثل', 'برامج', 'الدعم', 'تلك', 'كل', 'ما', 'تطمع', 'وتشتهيه', 'من', 'سلع', '،', 'ولكنك', 'ستجد', 'بها', 'الحد', 'الأدنى', 'من', 'احتياجاتك', 'من', 'الأطعمة', 'الصحية', 'والضروريات', 'اللازمة', 'من', 'الطعام', '.', '  ', 'اذهب', 'إلى', 'المكتب', 'المحلي', 'المخصص', 'للتقدم', 'بطلب', 'الحصول', 'على', 'الدعم', 'أو', 'يمكنك', 'التقدم', 'عبر', 'المنصات', 'والمواقع', 'الإلكترونية', 'في', 'حال', 'توفرها', '.', 'تواصلي', 'مع', 'الجهات', 'المسؤولة', 'عن', 'تقديم', 'الدعم', 'للعاطلين', 'وللسيدات', 'محدودات', 'الدخل', 'وما', 'شابه', 'في', 'مدينتك', 'لمعرفة', 'كيفية', 'التقدم', 'للاشتراك', 'في', 'برامج', 'الدعم', 'المماثلة', '.', 'تجد', 'العديد', 'من', 'السلع', 'الغذائية', 'الأرخص', 'سعرا', 'في', 'المتاجر', 'التابعة', 'مباشرة', 'للمزارع', 'المحلية', '،', 'وإن', 'كنت', 'ستواجه', 'صعوبة', 'في', 'الحصول', 'على', 'احتياجك', 'من', 'السلع', 'نظرا', 'لضغط', 'الطلب', 'وقلة', 'المعروض', 'من', 'منتجات', 'غالبا', '.', 'إنها', 'أطعمة', 'طازجة', 'ولم', 'يضاف', 'إليها', 'تكاليف', 'النقل', 'وأرباح', 'الكثير', 'من', 'الموزعين', 'والبائعين', '،', 'لذا', 'ستقدر', 'على', 'الحصول', 'عليها', 'بسعر', 'أرخص', 'وجودة', 'أفضل', '.', 'استوعب', 'فقط', 'أنك', 'لن', 'تملك', 'رفاهية', 'تأجيل', 'تناولها', 'كونها', 'لا', 'تظل', 'على', 'حالتها', 'فترات', 'طويلة', 'مقارنة', 'بغيرها', 'من', 'السلع', 'الغذائية', 'المزروعة', 'لتحمل', 'مشقة', 'النقل', 'والفترات', 'الزمنية', 'الطويلة', 'قبل', 'التناول', '.', 'الميزة', 'الإيجابية', 'أنك', 'ستقدر', 'على', 'تناول', 'أطعمة', 'أفضل', 'مذاقا', 'وطزاجة', '.', ' ', 'قد', 'تجد', 'بعض', 'المزارع', 'المحلية', 'المدرجة', 'ضمن', 'برامج', 'الدعم', 'الحكومي', 'للطعام', 'والتي', 'توفر', 'للمستحقين', 'إمكانية', 'شراء', 'الفاكهة', 'والخضراوات', 'بسعر', 'أقل', '.']\n"
          ]
        }
      ],
      "source": [
        "sample = dataset['text'][0]\n",
        "print(\"Original:\", sample)\n",
        "print(\"Tokens:\", tokenize_ar(sample))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Clean and Re-tokenize Text\n",
        "\n",
        "Defines a `clean_text` function to:\n",
        "- Remove punctuation\n",
        "- Remove digits\n",
        "- Strip whitespace\n",
        "\n",
        "Then redefines `tokenize_ar` to include cleaning before tokenization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yip17qkwGobq"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def tokenize_ar(text):\n",
        "    text = clean_text(text)\n",
        "    return [tok.text for tok in nlp(text)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Re-check Tokenization (Duplicate)\n",
        "\n",
        "This appears to repeat the earlier sample preview.  \n",
        "May be removed or kept to confirm tokenization after text cleaning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-ASQv3XGt5p",
        "outputId": "06d3e2c7-b99d-4a71-a3b4-cbae415026a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: يكون سعر الفاكهة والخضراوات في موسم إنباتها أقل من غيره من المواسم، وستلجأ محلات الخضروات إلى عرض الفاكهة بأسعار مناسبة في موسمها بسبب توفر المنتجات وزيادة الطلب عليها خلال تلك الفترات. لا يقتصر الأمر على السعر الأقل، بل سيكون طعامك من الخضراوات والفاكهة أشهى وألذ عند تناوله في موسمه.   في فصل الخريف: التفاح والتين والبنجر والكمثرى والقرنبيط والكرنب واليقطين في فصل الشتاء: (الخضراوات) الملفوف والفاصوليا والبازلاء والبصل (الفواكه)  البطاطا الحلوة والأفوكادو والبرتقال والتفاح والموز واليوسفى والرمان والعنب. في فصل الربيع: السبانخ والجزر والكوسة والبصل الأخضر  والطماطم والخضراوات الورقية والفراولة والمشمش. في فصل الصيف: الصيف هو فصل البطيخ، وكذلك الأمر بالنسبة للذرة والتوت. سوف تلاحظ توفر هذه الخضراوات والفواكهة المهمة على مدار العام كله بشكل أو آخر، ولكنها تكون بأرخص أسعارها في فصل الصيف، وهو ما يمكنك من شراء كميات كبيرة منها وتخزينها أو تجميدها في المجمد (الفريزر). الأفضل لصحتك البدنية والمالية على حد سواء هو تناول الفواكه والخضراوات والأطعمة الطازجة عامة، ولكن في بعض الحالات قد يكون من الأرخص بالنسبة لك الاعتماد على الطعام المعبأ. سوف تحصل منه على نفس الفوائد الغذائية بشرط التأكد من أنه غير مضاف إليه أي ملح أو سكر أو مواد مصنعة.  اتبع هذه النصيحة مع الفواكه والخضراوات وكذلك مع مصادر البروتينات؛ قد يكون سعر الفراخ المجمدة مثلا أرخص من الطازجة، وبالمثل في حالة عبوات التونة والسالمون مقارنة بشراء السمك من كلا النوعين طازجا. تحرص العديد من محلات الأطعمة الغذائية باختلاف أنواعها على تقديم عروض خاصة لعملائها بوتيرة أسبوعية، وهو ما يمكنك الاطلاع عليه عبر مطبوعات الإعلانات وصفحاتهم الرسمية عبر وسائل التواصل الاجتماعي. اغتنم أوقات العروض على واحدة من الأطعمة وجهز نفسك واهجم على المحل لاقتناء أكبر كمية ممكنة على أمل تخزينها في منزلك بشكل أو آخر؛ إنها صفقة لا تعوض. يمكنك تخزين أغلبية أنواع اللحوم على سبيل المثال، لذا بمجرد رؤيتك لهذا العرض الخاص على صدور الدجاج في واحدة من المحلات الكبرى، أسرع فورا واشتر كمية مناسبة يمكنك تخزين الزائد منها عن حاجتك لوقت لاحق. إنها مهارة تتقنها كل ربات البيوت وإلا لما نجحت جداتنا وأمهاتنا في تربية عدد ضخم من الأبناء بقدر ضئيل من المرتبات، وبنسبة كبيرة أنك تحرصين بدورك على شراء أرخص العلامات التجارية المقبولة وقد سبق لك إجراء مثل هذه المقارنة، لكن ما نود الإشارة إليه هو عدم الارتكان دائما لنفس خيار الشراء بوصفه الأرخص ثمنا، لأنه ربما كان كذلك منذ شهور، بينما قد توفر في السوق الآن خيار بديل بسعر أفضل. عملية المقارنة بين الأسعار مهمة ضرورية قبل كل عملية شراء قدر الإمكان، لذا لا تفقدي يقظتك أبدا. عادة ما يتاح كذلك عروض مميزة على شراء الكميات الكبيرة أو خصما على منتج معين لفترة محدودة، لذا من خلال عملية البحث والمقارنة المستمرة يمكنك الذهاب إلى السوق وشراء كل ما يلزمك بأفضل سعر ممكن.    انقلي بصرك لأعلى وأسفل رفوف المحلات التجارية، فغالبا ما يتعمد البائعون وضع السلع الأغلى ثمنا في مستوى العين لكي يبادر المستهلكون دائما لاقتنائها وإغفال النظر عن غيرها من الخيارات رخيصة الثمن. ابحثي عن السلع والأطعمة المحلية والمصنعة باسم المتجر التجاري نفسه، والتي عادة ما تكون بسعر أقل مقارنة بالعلامات التجارية الكبرى. سوف تقف أمام البائع وتدفع رقما ضخما نظير شرائك للسلع بالجملة، ولكن بحسبة بسيطة ستكتشف أنك حصلت على الوحدة الواحدة من المنتج بثمن أرخص من الشراء بالقطعة. توجد متاجر خاصة بالبيع بالجملة كما يتوفر هذا الاختيار في كل المحلات العادية كذلك؛ عند شرائك لدستة من منتج معين، سيكون إجمالي السعر أرخص من شراء نفس عدد العبوات بشكل منفرد على أكثر من مرة.   يمكنك الشراء بالجملة من متاجر السلع المعبئة (السوبرماركت) ونفس الأمر بالنسبة لمحلات الفاكهة والخضراوات والسلع الغذائية الصحية (العضوية). يحرص البائعون على توفير سلع مثل: الحبوب والبقول والمكرونة (غير المعبئة) والمكسرات والدقيق والسكر وما شابه، للشراء بالجملة. حاول شراء السلع سابقة الذكر من المحلات المدعومة تبعا لوزارة التموين في بلدك، فقد تحصل منها على نفس السلع بنفس جودة العلامات التجارية الكبرى ولكن بسعر مخفض. ضع نصب عينيك حقيقة وجود فترة زمنية قصوى يمكنك خلالها استهلاك ما اشتريته من سلع بالجملة، فمهما كان من الممكن تخزينها أو تجميدها، ستجد نفسك أمام حقيقة أن ما اشتريته معرضا لانتهاء صلاحيته بعد عدة شهور. استوعب مناسبة تلك الكمية الكبيرة لمعدل استهلاكك أنت وأسرتك (ورغبتهم في أكلها أصلا) من الأطعمة ودون أن تنسى إدراج فترة صلاحية المنتج ضمن تلك المعادلة الحسابية الصعبة، فلا فائدة من شراء شيء رخيص ولكنه سيلقى على الأرض بلا فائدة عندما يصبح غير صالح للاستخدام. لا تترك قسيمة شراء تهرب من تحت يدك بمجرد وجود فرصة للحصول عليها، لكن على الجانب الآخر لا تشتر سوى السلع والمنتجات التي تعرف أنك بحاجة إلى استخدامها. لا فائدة من شراء منتج لا تشتريه في العادة -مهما كان رخيص الثمن- لأنك ستنفق أموالك على ما لا تحتاجه وما لن ترغب في استخدامه، وستضيع أموالك على الأرض بلا فائدة، وستدرك وقتها أنها كانت صفقة خاسرة.  يمكنك إيجاد قسائم الشراء عبر الإنترنت أو في الجرائد والمجلات، كما يمكنك الاستفادة حديثا من تطبيقات قسائم الشراء على الهواتف الذكية. قد تكون مؤهلا للاشتراك في واحدة من برامج دعم الغذاء لمحدودي الدخل في بلدك، وهي الجهات التي توفر الطعام بأسعار مدعومة للمحتاجين.   تختلف أنظمة دعم التموين والطعام من بلد لآخر، لذانص مائل ستحتاج لإجراء عملية بحث بسيطة لمعرفة إجراءات التسجيل في مثل هذه البرامج. قد تجد برامج مخصصة للعاطلين من الأفراد أو السيدات قليلات الدخل أو للأسر كبيرة العدد وما شابه. قد لا تتوفر لك في المتاجر التابعة لمثل برامج الدعم تلك كل ما تطمع وتشتهيه من سلع، ولكنك ستجد بها الحد الأدنى من احتياجاتك من الأطعمة الصحية والضروريات اللازمة من الطعام.   اذهب إلى المكتب المحلي المخصص للتقدم بطلب الحصول على الدعم أو يمكنك التقدم عبر المنصات والمواقع الإلكترونية في حال توفرها. تواصلي مع الجهات المسؤولة عن تقديم الدعم للعاطلين وللسيدات محدودات الدخل وما شابه في مدينتك لمعرفة كيفية التقدم للاشتراك في برامج الدعم المماثلة. تجد العديد من السلع الغذائية الأرخص سعرا في المتاجر التابعة مباشرة للمزارع المحلية، وإن كنت ستواجه صعوبة في الحصول على احتياجك من السلع نظرا لضغط الطلب وقلة المعروض من منتجات غالبا. إنها أطعمة طازجة ولم يضاف إليها تكاليف النقل وأرباح الكثير من الموزعين والبائعين، لذا ستقدر على الحصول عليها بسعر أرخص وجودة أفضل. استوعب فقط أنك لن تملك رفاهية تأجيل تناولها كونها لا تظل على حالتها فترات طويلة مقارنة بغيرها من السلع الغذائية المزروعة لتحمل مشقة النقل والفترات الزمنية الطويلة قبل التناول. الميزة الإيجابية أنك ستقدر على تناول أطعمة أفضل مذاقا وطزاجة.  قد تجد بعض المزارع المحلية المدرجة ضمن برامج الدعم الحكومي للطعام والتي توفر للمستحقين إمكانية شراء الفاكهة والخضراوات بسعر أقل.\n",
            "Tokens: ['يكون', 'سعر', 'الفاكهة', 'والخضراوات', 'في', 'موسم', 'إنباتها', 'أقل', 'من', 'غيره', 'من', 'المواسم', 'وستلجأ', 'محلات', 'الخضروات', 'إلى', 'عرض', 'الفاكهة', 'بأسعار', 'مناسبة', 'في', 'موسمها', 'بسبب', 'توفر', 'المنتجات', 'وزيادة', 'الطلب', 'عليها', 'خلال', 'تلك', 'الفترات', 'لا', 'يقتصر', 'الأمر', 'على', 'السعر', 'الأقل', 'بل', 'سيكون', 'طعامك', 'من', 'الخضراوات', 'والفاكهة', 'أشهى', 'وألذ', 'عند', 'تناوله', 'في', 'موسمه', '  ', 'في', 'فصل', 'الخريف', 'التفاح', 'والتين', 'والبنجر', 'والكمثرى', 'والقرنبيط', 'والكرنب', 'واليقطين', 'في', 'فصل', 'الشتاء', 'الخضراوات', 'الملفوف', 'والفاصوليا', 'والبازلاء', 'والبصل', 'الفواكه', ' ', 'البطاطا', 'الحلوة', 'والأفوكادو', 'والبرتقال', 'والتفاح', 'والموز', 'واليوسفى', 'والرمان', 'والعنب', 'في', 'فصل', 'الربيع', 'السبانخ', 'والجزر', 'والكوسة', 'والبصل', 'الأخضر', ' ', 'والطماطم', 'والخضراوات', 'الورقية', 'والفراولة', 'والمشمش', 'في', 'فصل', 'الصيف', 'الصيف', 'هو', 'فصل', 'البطيخ', 'وكذلك', 'الأمر', 'بالنسبة', 'للذرة', 'والتوت', 'سوف', 'تلاحظ', 'توفر', 'هذه', 'الخضراوات', 'والفواكهة', 'المهمة', 'على', 'مدار', 'العام', 'كله', 'بشكل', 'أو', 'آخر', 'ولكنها', 'تكون', 'بأرخص', 'أسعارها', 'في', 'فصل', 'الصيف', 'وهو', 'ما', 'يمكنك', 'من', 'شراء', 'كميات', 'كبيرة', 'منها', 'وتخزينها', 'أو', 'تجميدها', 'في', 'المجمد', 'الفريزر', 'الأفضل', 'لصحتك', 'البدنية', 'والمالية', 'على', 'حد', 'سواء', 'هو', 'تناول', 'الفواكه', 'والخضراوات', 'والأطعمة', 'الطازجة', 'عامة', 'ولكن', 'في', 'بعض', 'الحالات', 'قد', 'يكون', 'من', 'الأرخص', 'بالنسبة', 'لك', 'الاعتماد', 'على', 'الطعام', 'المعبأ', 'سوف', 'تحصل', 'منه', 'على', 'نفس', 'الفوائد', 'الغذائية', 'بشرط', 'التأكد', 'من', 'أنه', 'غير', 'مضاف', 'إليه', 'أي', 'ملح', 'أو', 'سكر', 'أو', 'مواد', 'مصنعة', ' ', 'اتبع', 'هذه', 'النصيحة', 'مع', 'الفواكه', 'والخضراوات', 'وكذلك', 'مع', 'مصادر', 'البروتينات', 'قد', 'يكون', 'سعر', 'الفراخ', 'المجمدة', 'مثلا', 'أرخص', 'من', 'الطازجة', 'وبالمثل', 'في', 'حالة', 'عبوات', 'التونة', 'والسالمون', 'مقارنة', 'بشراء', 'السمك', 'من', 'كلا', 'النوعين', 'طازجا', 'تحرص', 'العديد', 'من', 'محلات', 'الأطعمة', 'الغذائية', 'باختلاف', 'أنواعها', 'على', 'تقديم', 'عروض', 'خاصة', 'لعملائها', 'بوتيرة', 'أسبوعية', 'وهو', 'ما', 'يمكنك', 'الاطلاع', 'عليه', 'عبر', 'مطبوعات', 'الإعلانات', 'وصفحاتهم', 'الرسمية', 'عبر', 'وسائل', 'التواصل', 'الاجتماعي', 'اغتنم', 'أوقات', 'العروض', 'على', 'واحدة', 'من', 'الأطعمة', 'وجهز', 'نفسك', 'واهجم', 'على', 'المحل', 'لاقتناء', 'أكبر', 'كمية', 'ممكنة', 'على', 'أمل', 'تخزينها', 'في', 'منزلك', 'بشكل', 'أو', 'آخر', 'إنها', 'صفقة', 'لا', 'تعوض', 'يمكنك', 'تخزين', 'أغلبية', 'أنواع', 'اللحوم', 'على', 'سبيل', 'المثال', 'لذا', 'بمجرد', 'رؤيتك', 'لهذا', 'العرض', 'الخاص', 'على', 'صدور', 'الدجاج', 'في', 'واحدة', 'من', 'المحلات', 'الكبرى', 'أسرع', 'فورا', 'واشتر', 'كمية', 'مناسبة', 'يمكنك', 'تخزين', 'الزائد', 'منها', 'عن', 'حاجتك', 'لوقت', 'لاحق', 'إنها', 'مهارة', 'تتقنها', 'كل', 'ربات', 'البيوت', 'وإلا', 'لما', 'نجحت', 'جداتنا', 'وأمهاتنا', 'في', 'تربية', 'عدد', 'ضخم', 'من', 'الأبناء', 'بقدر', 'ضئيل', 'من', 'المرتبات', 'وبنسبة', 'كبيرة', 'أنك', 'تحرصين', 'بدورك', 'على', 'شراء', 'أرخص', 'العلامات', 'التجارية', 'المقبولة', 'وقد', 'سبق', 'لك', 'إجراء', 'مثل', 'هذه', 'المقارنة', 'لكن', 'ما', 'نود', 'الإشارة', 'إليه', 'هو', 'عدم', 'الارتكان', 'دائما', 'لنفس', 'خيار', 'الشراء', 'بوصفه', 'الأرخص', 'ثمنا', 'لأنه', 'ربما', 'كان', 'كذلك', 'منذ', 'شهور', 'بينما', 'قد', 'توفر', 'في', 'السوق', 'الآن', 'خيار', 'بديل', 'بسعر', 'أفضل', 'عملية', 'المقارنة', 'بين', 'الأسعار', 'مهمة', 'ضرورية', 'قبل', 'كل', 'عملية', 'شراء', 'قدر', 'الإمكان', 'لذا', 'لا', 'تفقدي', 'يقظتك', 'أبدا', 'عادة', 'ما', 'يتاح', 'كذلك', 'عروض', 'مميزة', 'على', 'شراء', 'الكميات', 'الكبيرة', 'أو', 'خصما', 'على', 'منتج', 'معين', 'لفترة', 'محدودة', 'لذا', 'من', 'خلال', 'عملية', 'البحث', 'والمقارنة', 'المستمرة', 'يمكنك', 'الذهاب', 'إلى', 'السوق', 'وشراء', 'كل', 'ما', 'يلزمك', 'بأفضل', 'سعر', 'ممكن', '   ', 'انقلي', 'بصرك', 'لأعلى', 'وأسفل', 'رفوف', 'المحلات', 'التجارية', 'فغالبا', 'ما', 'يتعمد', 'البائعون', 'وضع', 'السلع', 'الأغلى', 'ثمنا', 'في', 'مستوى', 'العين', 'لكي', 'يبادر', 'المستهلكون', 'دائما', 'لاقتنائها', 'وإغفال', 'النظر', 'عن', 'غيرها', 'من', 'الخيارات', 'رخيصة', 'الثمن', 'ابحثي', 'عن', 'السلع', 'والأطعمة', 'المحلية', 'والمصنعة', 'باسم', 'المتجر', 'التجاري', 'نفسه', 'والتي', 'عادة', 'ما', 'تكون', 'بسعر', 'أقل', 'مقارنة', 'بالعلامات', 'التجارية', 'الكبرى', 'سوف', 'تقف', 'أمام', 'البائع', 'وتدفع', 'رقما', 'ضخما', 'نظير', 'شرائك', 'للسلع', 'بالجملة', 'ولكن', 'بحسبة', 'بسيطة', 'ستكتشف', 'أنك', 'حصلت', 'على', 'الوحدة', 'الواحدة', 'من', 'المنتج', 'بثمن', 'أرخص', 'من', 'الشراء', 'بالقطعة', 'توجد', 'متاجر', 'خاصة', 'بالبيع', 'بالجملة', 'كما', 'يتوفر', 'هذا', 'الاختيار', 'في', 'كل', 'المحلات', 'العادية', 'كذلك', 'عند', 'شرائك', 'لدستة', 'من', 'منتج', 'معين', 'سيكون', 'إجمالي', 'السعر', 'أرخص', 'من', 'شراء', 'نفس', 'عدد', 'العبوات', 'بشكل', 'منفرد', 'على', 'أكثر', 'من', 'مرة', '  ', 'يمكنك', 'الشراء', 'بالجملة', 'من', 'متاجر', 'السلع', 'المعبئة', 'السوبرماركت', 'ونفس', 'الأمر', 'بالنسبة', 'لمحلات', 'الفاكهة', 'والخضراوات', 'والسلع', 'الغذائية', 'الصحية', 'العضوية', 'يحرص', 'البائعون', 'على', 'توفير', 'سلع', 'مثل', 'الحبوب', 'والبقول', 'والمكرونة', 'غير', 'المعبئة', 'والمكسرات', 'والدقيق', 'والسكر', 'وما', 'شابه', 'للشراء', 'بالجملة', 'حاول', 'شراء', 'السلع', 'سابقة', 'الذكر', 'من', 'المحلات', 'المدعومة', 'تبعا', 'لوزارة', 'التموين', 'في', 'بلدك', 'فقد', 'تحصل', 'منها', 'على', 'نفس', 'السلع', 'بنفس', 'جودة', 'العلامات', 'التجارية', 'الكبرى', 'ولكن', 'بسعر', 'مخفض', 'ضع', 'نصب', 'عينيك', 'حقيقة', 'وجود', 'فترة', 'زمنية', 'قصوى', 'يمكنك', 'خلالها', 'استهلاك', 'ما', 'اشتريته', 'من', 'سلع', 'بالجملة', 'فمهما', 'كان', 'من', 'الممكن', 'تخزينها', 'أو', 'تجميدها', 'ستجد', 'نفسك', 'أمام', 'حقيقة', 'أن', 'ما', 'اشتريته', 'معرضا', 'لانتهاء', 'صلاحيته', 'بعد', 'عدة', 'شهور', 'استوعب', 'مناسبة', 'تلك', 'الكمية', 'الكبيرة', 'لمعدل', 'استهلاكك', 'أنت', 'وأسرتك', 'ورغبتهم', 'في', 'أكلها', 'أصلا', 'من', 'الأطعمة', 'ودون', 'أن', 'تنسى', 'إدراج', 'فترة', 'صلاحية', 'المنتج', 'ضمن', 'تلك', 'المعادلة', 'الحسابية', 'الصعبة', 'فلا', 'فائدة', 'من', 'شراء', 'شيء', 'رخيص', 'ولكنه', 'سيلقى', 'على', 'الأرض', 'بلا', 'فائدة', 'عندما', 'يصبح', 'غير', 'صالح', 'للاستخدام', 'لا', 'تترك', 'قسيمة', 'شراء', 'تهرب', 'من', 'تحت', 'يدك', 'بمجرد', 'وجود', 'فرصة', 'للحصول', 'عليها', 'لكن', 'على', 'الجانب', 'الآخر', 'لا', 'تشتر', 'سوى', 'السلع', 'والمنتجات', 'التي', 'تعرف', 'أنك', 'بحاجة', 'إلى', 'استخدامها', 'لا', 'فائدة', 'من', 'شراء', 'منتج', 'لا', 'تشتريه', 'في', 'العادة', 'مهما', 'كان', 'رخيص', 'الثمن', 'لأنك', 'ستنفق', 'أموالك', 'على', 'ما', 'لا', 'تحتاجه', 'وما', 'لن', 'ترغب', 'في', 'استخدامه', 'وستضيع', 'أموالك', 'على', 'الأرض', 'بلا', 'فائدة', 'وستدرك', 'وقتها', 'أنها', 'كانت', 'صفقة', 'خاسرة', ' ', 'يمكنك', 'إيجاد', 'قسائم', 'الشراء', 'عبر', 'الإنترنت', 'أو', 'في', 'الجرائد', 'والمجلات', 'كما', 'يمكنك', 'الاستفادة', 'حديثا', 'من', 'تطبيقات', 'قسائم', 'الشراء', 'على', 'الهواتف', 'الذكية', 'قد', 'تكون', 'مؤهلا', 'للاشتراك', 'في', 'واحدة', 'من', 'برامج', 'دعم', 'الغذاء', 'لمحدودي', 'الدخل', 'في', 'بلدك', 'وهي', 'الجهات', 'التي', 'توفر', 'الطعام', 'بأسعار', 'مدعومة', 'للمحتاجين', '  ', 'تختلف', 'أنظمة', 'دعم', 'التموين', 'والطعام', 'من', 'بلد', 'لآخر', 'لذانص', 'مائل', 'ستحتاج', 'لإجراء', 'عملية', 'بحث', 'بسيطة', 'لمعرفة', 'إجراءات', 'التسجيل', 'في', 'مثل', 'هذه', 'البرامج', 'قد', 'تجد', 'برامج', 'مخصصة', 'للعاطلين', 'من', 'الأفراد', 'أو', 'السيدات', 'قليلات', 'الدخل', 'أو', 'للأسر', 'كبيرة', 'العدد', 'وما', 'شابه', 'قد', 'لا', 'تتوفر', 'لك', 'في', 'المتاجر', 'التابعة', 'لمثل', 'برامج', 'الدعم', 'تلك', 'كل', 'ما', 'تطمع', 'وتشتهيه', 'من', 'سلع', 'ولكنك', 'ستجد', 'بها', 'الحد', 'الأدنى', 'من', 'احتياجاتك', 'من', 'الأطعمة', 'الصحية', 'والضروريات', 'اللازمة', 'من', 'الطعام', '  ', 'اذهب', 'إلى', 'المكتب', 'المحلي', 'المخصص', 'للتقدم', 'بطلب', 'الحصول', 'على', 'الدعم', 'أو', 'يمكنك', 'التقدم', 'عبر', 'المنصات', 'والمواقع', 'الإلكترونية', 'في', 'حال', 'توفرها', 'تواصلي', 'مع', 'الجهات', 'المسؤولة', 'عن', 'تقديم', 'الدعم', 'للعاطلين', 'وللسيدات', 'محدودات', 'الدخل', 'وما', 'شابه', 'في', 'مدينتك', 'لمعرفة', 'كيفية', 'التقدم', 'للاشتراك', 'في', 'برامج', 'الدعم', 'المماثلة', 'تجد', 'العديد', 'من', 'السلع', 'الغذائية', 'الأرخص', 'سعرا', 'في', 'المتاجر', 'التابعة', 'مباشرة', 'للمزارع', 'المحلية', 'وإن', 'كنت', 'ستواجه', 'صعوبة', 'في', 'الحصول', 'على', 'احتياجك', 'من', 'السلع', 'نظرا', 'لضغط', 'الطلب', 'وقلة', 'المعروض', 'من', 'منتجات', 'غالبا', 'إنها', 'أطعمة', 'طازجة', 'ولم', 'يضاف', 'إليها', 'تكاليف', 'النقل', 'وأرباح', 'الكثير', 'من', 'الموزعين', 'والبائعين', 'لذا', 'ستقدر', 'على', 'الحصول', 'عليها', 'بسعر', 'أرخص', 'وجودة', 'أفضل', 'استوعب', 'فقط', 'أنك', 'لن', 'تملك', 'رفاهية', 'تأجيل', 'تناولها', 'كونها', 'لا', 'تظل', 'على', 'حالتها', 'فترات', 'طويلة', 'مقارنة', 'بغيرها', 'من', 'السلع', 'الغذائية', 'المزروعة', 'لتحمل', 'مشقة', 'النقل', 'والفترات', 'الزمنية', 'الطويلة', 'قبل', 'التناول', 'الميزة', 'الإيجابية', 'أنك', 'ستقدر', 'على', 'تناول', 'أطعمة', 'أفضل', 'مذاقا', 'وطزاجة', ' ', 'قد', 'تجد', 'بعض', 'المزارع', 'المحلية', 'المدرجة', 'ضمن', 'برامج', 'الدعم', 'الحكومي', 'للطعام', 'والتي', 'توفر', 'للمستحقين', 'إمكانية', 'شراء', 'الفاكهة', 'والخضراوات', 'بسعر', 'أقل']\n"
          ]
        }
      ],
      "source": [
        "sample = dataset['text'][0]\n",
        "print(\"Original:\", sample)\n",
        "print(\"Tokens:\", tokenize_ar(sample))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build Vocabularies\n",
        "\n",
        "This function:\n",
        "- Builds token frequency counters for both source texts and summaries\n",
        "- Filters out rare words (appearing < 2 times)\n",
        "- Adds special tokens: `<pad>`, `<sos>`, `<eos>`, `<unk>`\n",
        "- Assigns each token an index to create a vocabulary dictionary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8XVtTSuHLx4",
        "outputId": "6220b0e6-2ef0-445f-cde4-4005938dae72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "عدد كلمات النص: 132722\n",
            "عدد كلمات التلخيص: 33874\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "dataset.dropna(inplace=True)\n",
        "\n",
        "def build_vocab(texts, min_freq=2):\n",
        "    counter = Counter()\n",
        "    for txt in texts:\n",
        "        tokens = tokenize_ar(txt)\n",
        "        counter.update(tokens)\n",
        "\n",
        "    vocab = {\n",
        "        \"<pad>\": 0,\n",
        "        \"<sos>\": 1,\n",
        "        \"<eos>\": 2,\n",
        "        \"<unk>\": 3,\n",
        "    }\n",
        "\n",
        "    idx = 4\n",
        "    for word, freq in counter.items():\n",
        "        if freq >= min_freq:\n",
        "            vocab[word] = idx\n",
        "            idx += 1\n",
        "\n",
        "    return vocab\n",
        "\n",
        "\n",
        "text_vocab = build_vocab(dataset[\"text\"])\n",
        "summary_vocab = build_vocab(dataset[\"summary\"])\n",
        "\n",
        "print(\"عدد كلمات النص:\", len(text_vocab))\n",
        "print(\"عدد كلمات التلخيص:\", len(summary_vocab))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Numericalize Text\n",
        "\n",
        "This function:\n",
        "- Converts tokens to integers using the vocabulary\n",
        "- Optionally adds `<sos>` and `<eos>` tokens for decoder input\n",
        "- Pads/truncates the sequence to a fixed maximum length\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ILAv1aXLq2c"
      },
      "outputs": [],
      "source": [
        "def numericalize(text, vocab, add_sos_eos=False, max_len=100):\n",
        "    tokens = tokenize_ar(text)\n",
        "    if add_sos_eos:\n",
        "        tokens = [\"<sos>\"] + tokens + [\"<eos>\"]\n",
        "\n",
        "    ids = [vocab.get(tok, vocab[\"<unk>\"]) for tok in tokens]\n",
        "\n",
        "\n",
        "    if len(ids) < max_len:\n",
        "        ids += [vocab[\"<pad>\"]] * (max_len - len(ids))\n",
        "    else:\n",
        "        ids = ids[:max_len]\n",
        "\n",
        "    return ids\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vectorize the Dataset\n",
        "\n",
        "This cell applies the `numericalize` function to the entire dataset:\n",
        "- Source texts are converted to fixed-length vectors of 150 tokens\n",
        "- Summaries are encoded with `<sos>` and `<eos>` for a max length of 50 tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMEJsp9aLrkF"
      },
      "outputs": [],
      "source": [
        "MAX_TEXT_LEN = 150\n",
        "MAX_SUMMARY_LEN = 50\n",
        "\n",
        "text_seqs = [numericalize(txt, text_vocab, add_sos_eos=False, max_len=MAX_TEXT_LEN)\n",
        "             for txt in dataset[\"text\"]]\n",
        "\n",
        "summary_seqs = [numericalize(txt, summary_vocab, add_sos_eos=True, max_len=MAX_SUMMARY_LEN)\n",
        "                for txt in dataset[\"summary\"]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create PyTorch Dataset Class\n",
        "\n",
        "Defines a custom `Dataset` class compatible with PyTorch `DataLoader`.  \n",
        "Each example includes:\n",
        "- `input`: vectorized source sentence\n",
        "- `target`: vectorized summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hztnn784UVUn"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class SummarizationDataset(Dataset):\n",
        "    def __init__(self, inputs, targets):\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input': torch.tensor(self.inputs[idx], dtype=torch.long),\n",
        "            'target': torch.tensor(self.targets[idx], dtype=torch.long)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split into Train and Validation Sets\n",
        "\n",
        "Splits the numericalized dataset into 80% training and 20% validation.  \n",
        "Creates corresponding `SummarizationDataset` objects.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsW5WcQAUWDV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_texts, val_texts, train_summaries, val_summaries = train_test_split(\n",
        "    text_seqs, summary_seqs, test_size=0.2, random_state=42)\n",
        "\n",
        "train_dataset = SummarizationDataset(train_texts, train_summaries)\n",
        "val_dataset = SummarizationDataset(val_texts, val_summaries)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create DataLoaders\n",
        "\n",
        "Wraps datasets into PyTorch `DataLoader` objects with:\n",
        "- Batch size: 32\n",
        "- Shuffling enabled for training set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXtWw9OWUYK4"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Encoder Module\n",
        "\n",
        "The Encoder:\n",
        "- Embeds input token indices\n",
        "- Processes sequences using a single-layer LSTM\n",
        "- Outputs the hidden states and final memory states to pass to the decoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhBfTylqUaco"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True, bidirectional=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        return outputs, hidden, cell\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Attention Mechanism\n",
        "\n",
        "This module computes attention scores by:\n",
        "- Comparing decoder hidden state to encoder outputs\n",
        "- Producing a distribution over the input sequence to weigh context\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2oDU2f5UiBq"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(Attention, self).__init__()\n",
        "        self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.v = nn.Linear(hidden_size, 1, bias=False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        src_len = encoder_outputs.shape[1]\n",
        "\n",
        "        hidden = hidden[-1].unsqueeze(1).repeat(1, src_len, 1)\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "\n",
        "        return torch.softmax(attention, dim=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Decoder with Attention\n",
        "\n",
        "The decoder:\n",
        "- Embeds the input summary token\n",
        "- Applies attention over the encoder outputs to create a context vector\n",
        "- Concatenates embedding + context to generate a prediction for the next word\n",
        "- Repeats this step for each time step during training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtiNcmrtUoa-"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, attention, num_layers=1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embed_size + hidden_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "        self.attention = attention\n",
        "\n",
        "    def forward(self, input, hidden, cell, encoder_outputs):\n",
        "        input = input.unsqueeze(1)  # [B] -> [B, 1]\n",
        "        embedded = self.embedding(input)  # [B, 1, E]\n",
        "\n",
        "        attn_weights = self.attention(hidden, encoder_outputs)  # [B, src_len]\n",
        "        attn_weights = attn_weights.unsqueeze(1)  # [B, 1, src_len]\n",
        "\n",
        "        context = torch.bmm(attn_weights, encoder_outputs)  # [B, 1, H]\n",
        "        rnn_input = torch.cat((embedded, context), dim=2)  # [B, 1, E+H]\n",
        "\n",
        "        outputs, (hidden, cell) = self.lstm(rnn_input, (hidden, cell))\n",
        "        predictions = self.fc(outputs.squeeze(1))  # [B, vocab]\n",
        "\n",
        "        return predictions, hidden, cell, attn_weights.squeeze(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Seq2Seq Model Wrapper\n",
        "\n",
        "This module combines the encoder and decoder:\n",
        "- Uses teacher forcing to mix true labels with predictions\n",
        "- Iteratively decodes summary tokens while attending to the encoder outputs\n",
        "- Stores all predictions in a tensor of shape [batch, trg_len, vocab_size]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q84-kMosUqQ9"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        batch_size = src.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        trg_vocab_size = self.decoder.fc.out_features\n",
        "\n",
        "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
        "\n",
        "        encoder_outputs, hidden, cell = self.encoder(src)\n",
        "\n",
        "        input = trg[:, 0]  # <sos>\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden, cell, _ = self.decoder(input, hidden, cell, encoder_outputs)\n",
        "            outputs[:, t] = output\n",
        "            top1 = output.argmax(1)\n",
        "            input = trg[:, t] if random.random() < teacher_forcing_ratio else top1\n",
        "\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize Model and Optimizer\n",
        "\n",
        "- Defines key hyperparameters (embedding, hidden size)\n",
        "- Instantiates encoder, decoder, and attention modules\n",
        "- Moves everything to GPU if available\n",
        "- Uses `CrossEntropyLoss` (ignoring `<pad>` tokens)\n",
        "- Adam optimizer with learning rate 0.001\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vh84k3keVF8p"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# المعلمات\n",
        "INPUT_DIM = len(text_vocab)\n",
        "OUTPUT_DIM = len(summary_vocab)\n",
        "EMBED_SIZE = 256\n",
        "HIDDEN_SIZE = 512\n",
        "\n",
        "# بناء النموذج\n",
        "attn = Attention(HIDDEN_SIZE)\n",
        "encoder = Encoder(INPUT_DIM, EMBED_SIZE, HIDDEN_SIZE).to(device)\n",
        "decoder = Decoder(OUTPUT_DIM, EMBED_SIZE, HIDDEN_SIZE, attn).to(device)\n",
        "model = Seq2Seq(encoder, decoder, device).to(device)\n",
        "\n",
        "# loss و optimizer\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training Function\n",
        "\n",
        "This function:\n",
        "- Trains the model for one epoch\n",
        "- Applies teacher forcing in the forward pass\n",
        "- Clips gradients to prevent exploding\n",
        "- Returns the average training loss per epoch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkojEYft4-tM"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion, clip=1):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for batch in iterator:\n",
        "        src = batch['input'].to(device)\n",
        "        trg = batch['target'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg)  # [batch, trg_len, vocab_size]\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[:, 1:].reshape(-1, output_dim)\n",
        "        trg = trg[:, 1:].reshape(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation Function\n",
        "\n",
        "Evaluates model performance on validation data:\n",
        "- Disables teacher forcing\n",
        "- Computes loss across entire validation set\n",
        "- Returns average loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvHZt8Dm5BPk"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            src = batch['input'].to(device)\n",
        "            trg = batch['target'].to(device)\n",
        "\n",
        "            output = model(src, trg, 0)  # No teacher forcing\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[:, 1:].reshape(-1, output_dim)\n",
        "            trg = trg[:, 1:].reshape(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training Loop\n",
        "\n",
        "Trains the model for 5 epochs:\n",
        "- Prints train and validation loss after each epoch\n",
        "- Helps monitor model learning and overfitting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "rTF5joFI5EZv",
        "outputId": "35d5d589-c418-47b3-b64e-7271720187ae"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-3418225327>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch+1}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-2803497722>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, iterator, criterion)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mtrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# No teacher forcing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0moutput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-3135854086>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtop1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-784391250>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, cell, encoder_outputs)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mrnn_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "N_EPOCHS = 5\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss = train(model, train_loader, optimizer, criterion)\n",
        "    val_loss = evaluate(model, val_loader, criterion)\n",
        "\n",
        "    print(f'Epoch {epoch+1}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "    print(f'\\t Val. Loss: {val_loss:.3f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Decode Token IDs to Text\n",
        "\n",
        "Utility function to:\n",
        "- Convert a list of token IDs back to readable Arabic text\n",
        "- Skip padding and special tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFbcoio_QJNa"
      },
      "outputs": [],
      "source": [
        "def ids_to_text(ids, vocab):\n",
        "    inv_vocab = {v: k for k, v in vocab.items()}\n",
        "    words = [inv_vocab.get(i, \"<unk>\") for i in ids]\n",
        "    return ' '.join([w for w in words if w not in [\"<pad>\", \"<sos>\", \"<eos>\"]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate Summary for New Input\n",
        "\n",
        "Uses the trained model to:\n",
        "- Encode the input text\n",
        "- Generate summary tokens step-by-step (greedy decoding)\n",
        "- Stop when `<eos>` token is predicted or max length is reached\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otNhKitNQKBP"
      },
      "outputs": [],
      "source": [
        "def summarize_text(model, input_text, text_vocab, summary_vocab, max_len=MAX_SUMMARY_LEN):\n",
        "    model.eval()\n",
        "    tokens = numericalize(input_text, text_vocab, max_len=MAX_TEXT_LEN)\n",
        "    src_tensor = torch.tensor(tokens).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden, cell = model.encoder(src_tensor)\n",
        "\n",
        "    outputs = [summary_vocab[\"<sos>\"]]\n",
        "    for _ in range(max_len):\n",
        "        prev_word = torch.tensor([outputs[-1]]).to(device)\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell, _ = model.decoder(prev_word, hidden, cell, encoder_outputs)\n",
        "        pred_token = output.argmax(1).item()\n",
        "        outputs.append(pred_token)\n",
        "        if pred_token == summary_vocab[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    return ids_to_text(outputs, summary_vocab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8X6PZQmQMco"
      },
      "outputs": [],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gradio Interface for Summarization\n",
        "\n",
        "Creates a web interface for the summarization model using **Gradio**:\n",
        "- Takes Arabic input in a textbox\n",
        "- Returns a generated summary from the trained model\n",
        "- Uses the `summarize_text()` function behind the scenes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKO1QvpXQZaL"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def gradio_summarize(input_text):\n",
        "    summary = summarize_text(model, input_text, text_vocab, summary_vocab)\n",
        "    return summary\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=gradio_summarize,\n",
        "    inputs=gr.Textbox(lines=10, label=\"النص الأصلي\"),\n",
        "    outputs=gr.Textbox(lines=5, label=\"التلخيص الناتج\"),\n",
        "    title=\"نموذج تلخيص باستخدام LSTM + Attention\",\n",
        "    description=\"أدخل نصًا عربيًا وسيقوم النموذج بإرجاع تلخيص له\"\n",
        ")\n",
        "\n",
        "demo.launch(share=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "In this task, we implemented an Arabic text summarization model using an Encoder-Decoder architecture with an attention mechanism.\n",
        "\n",
        "Key highlights:\n",
        "- The encoder processed input sequences with LSTM.\n",
        "- The decoder generated summary tokens with the help of learned attention over the input.\n",
        "- The model achieved reasonable results in generating concise summaries.\n",
        "- An interactive Gradio interface was built to demonstrate the model in action.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
